{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNNConfig(object):\n",
    "    \"\"\"CNN param\"\"\"\n",
    "\n",
    "    embedding_dim = 64  # word vector dimension\n",
    "    seq_length = 800  # sequense length\n",
    "    num_classes = 3  # class number\n",
    "    num_filters = 256  # kernel number\n",
    "    kernel_size = 5  # kernel size\n",
    "    vocab_size = 5000  # vocab size\n",
    "\n",
    "    hidden_dim = 128  # fully connected neuro number\n",
    "\n",
    "    dropout_keep_prob = 0.5  # dropout keeping rate\n",
    "    learning_rate = 1e-3  # learning rate\n",
    "\n",
    "    batch_size = 64  # batch size\n",
    "    num_epochs = 10  # total epoch number\n",
    "\n",
    "    print_per_batch = 10  # output iterations\n",
    "    save_per_batch = 10  # save tensorboard iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"text classification，CNN model\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, self.config.seq_length], name='input_x')\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, self.config.num_classes], name='input_y')\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "        self.cnn()\n",
    "\n",
    "    def cnn(self):\n",
    "        \"\"\"CNN model\"\"\"\n",
    "        # word embedding\n",
    "        with tf.device('/cpu:0'):\n",
    "            embedding = tf.get_variable('embedding', [self.config.vocab_size, self.config.embedding_dim])\n",
    "            embedding_inputs = tf.nn.embedding_lookup(embedding, self.input_x)\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            # CNN layer\n",
    "            conv = tf.layers.conv1d(embedding_inputs, self.config.num_filters, self.config.kernel_size, name='conv')\n",
    "            # global max pooling layer\n",
    "            gmp = tf.reduce_max(conv, reduction_indices=[1], name='gmp')\n",
    "\n",
    "        with tf.name_scope(\"score\"):\n",
    "            # fully connected layer，with dropout and ReLU\n",
    "            fc = tf.layers.dense(gmp, self.config.hidden_dim, name='fc1')\n",
    "            fc = tf.contrib.layers.dropout(fc, self.keep_prob)\n",
    "            fc = tf.nn.relu(fc)\n",
    "\n",
    "            # classifier\n",
    "            self.logits = tf.layers.dense(fc, self.config.num_classes, name='fc2')\n",
    "            self.y_pred_cls = tf.argmax(tf.nn.softmax(self.logits), 1)  # predictor\n",
    "\n",
    "        with tf.name_scope(\"optimize\"):\n",
    "            # loss function，cross entropy\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(cross_entropy)\n",
    "            # optimizor\n",
    "            self.optim = tf.train.AdamOptimizer(learning_rate=self.config.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            # accuracy\n",
    "            correct_pred = tf.equal(tf.argmax(self.input_y, 1), self.y_pred_cls)\n",
    "            self.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/textcnn'\n",
    "save_path = os.path.join(save_dir, 'best_validation')\n",
    "param_saving_path = '../data/param-classify.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x, y, batch_size=64):\n",
    "    \"\"\"generate batchsize data\"\"\"\n",
    "    data_len = len(x)\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuffle = x[indices]\n",
    "    y_shuffle = y[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dif(start_time):\n",
    "    \"\"\"get time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "def feed_data(x_batch, y_batch, keep_prob):\n",
    "    feed_dict = {\n",
    "        model.input_x: x_batch,\n",
    "        model.input_y: y_batch,\n",
    "        model.keep_prob: keep_prob\n",
    "    }\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def evaluate(sess, x_, y_):\n",
    "    \"\"\"evaluate the loss and accuracy\"\"\"\n",
    "    data_len = len(x_)\n",
    "    batch_eval = batch_iter(x_, y_, 128)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    for x_batch, y_batch in batch_eval:\n",
    "        batch_len = len(x_batch)\n",
    "        feed_dict = feed_data(x_batch, y_batch, 1.0)\n",
    "        loss, acc = sess.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "        total_loss += loss * batch_len\n",
    "        total_acc += acc * batch_len\n",
    "\n",
    "    return total_loss / data_len, total_acc / data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tensorboard_dir = 'tensorboard/textcnn'\n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        os.makedirs(tensorboard_dir)\n",
    "\n",
    "    tf.summary.scalar(\"loss\", model.loss)\n",
    "    tf.summary.scalar(\"accuracy\", model.acc)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(tensorboard_dir)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    validation_rate = 0.1\n",
    "    idx = int(x.shape[0] * validation_rate)\n",
    "    x_train = x[idx:]\n",
    "    x_val = x[:idx]\n",
    "    y_train = y[idx:]\n",
    "    y_val = y[:idx]\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_val.shape)\n",
    "    \n",
    "    \n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    writer.add_graph(session.graph)\n",
    "    \n",
    "    print('Training and evaluating...')\n",
    "    start_time = time.time()\n",
    "    total_batch = 0  # total batch number\n",
    "    best_acc_val = 0.0  # best validation accuracy\n",
    "    last_improved = 0  # last improving\n",
    "    require_improvement = 1000  # if not improving after 1000 iterations, end early\n",
    "    \n",
    "    flag = False\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch:', epoch + 1)\n",
    "        batch_train = batch_iter(x_train, y_train, config.batch_size)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            feed_dict = feed_data(x_batch, y_batch, config.dropout_keep_prob)\n",
    "            \n",
    "            if total_batch % config.save_per_batch == 0:\n",
    "                # save to tensorboard scalar\n",
    "                s = session.run(merged_summary, feed_dict=feed_dict)\n",
    "                writer.add_summary(s, total_batch)\n",
    "\n",
    "\n",
    "            if total_batch % config.print_per_batch == 0:\n",
    "                # get the loss and accuracy on training set and validation set\n",
    "                feed_dict[model.keep_prob] = 1.0\n",
    "                loss_train, acc_train = session.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "                loss_val, acc_val = evaluate(session, x_val, y_val)  # todo\n",
    "\n",
    "                if acc_val > best_acc_val:\n",
    "                    # save the best result\n",
    "                    best_acc_val = acc_val\n",
    "                    last_improved = total_batch\n",
    "                    saver.save(sess=session, save_path=save_path)\n",
    "                    print(\"Save model!\")\n",
    "                    improved_str = '*'\n",
    "                else:\n",
    "                    improved_str = ''\n",
    "\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = 'Iter: {0:>6}, Train Loss: {1:>4.4}, Train Acc: {2:>5.2%},' \\\n",
    "                      + ' Val Loss: {3:>4.4}, Val Acc: {4:>5.2%}, Time: {5} {6}'\n",
    "                print(msg.format(total_batch, loss_train, acc_train, loss_val, acc_val, time_dif, improved_str))\n",
    "\n",
    "            session.run(model.optim, feed_dict=feed_dict)  # 运行优化\n",
    "            total_batch += 1\n",
    "\n",
    "            if total_batch - last_improved > require_improvement:\n",
    "                # early end\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break \n",
    "        if flag:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "config = TCNNConfig()\n",
    "with open(param_saving_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "print(len(x))\n",
    "P = np.random.permutation(len(x))\n",
    "x = x[P]\n",
    "y = y[P]\n",
    "\n",
    "wordToID = data['wordToID']\n",
    "seq_length = data['seq_length']\n",
    "config.vocab_size = len(wordToID)\n",
    "config.seq_length = seq_length\n",
    "\n",
    "model = TextCNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 800)\n",
      "(1500, 800)\n",
      "(13500, 3)\n",
      "(1500, 3)\n",
      "Training and evaluating...\n",
      "Epoch: 1\n",
      "Save model!\n",
      "Iter:      0, Train Loss: 1.096, Train Acc: 40.62%, Val Loss: 1.099, Val Acc: 34.80%, Time: 0:00:05 *\n",
      "Iter:     10, Train Loss: 1.105, Train Acc: 32.81%, Val Loss: 1.097, Val Acc: 32.33%, Time: 0:00:19 \n",
      "Save model!\n",
      "Iter:     20, Train Loss: 1.075, Train Acc: 34.38%, Val Loss: 1.079, Val Acc: 36.13%, Time: 0:00:32 *\n",
      "Save model!\n",
      "Iter:     30, Train Loss: 1.026, Train Acc: 51.56%, Val Loss: 1.026, Val Acc: 60.67%, Time: 0:00:46 *\n",
      "Save model!\n",
      "Iter:     40, Train Loss: 0.9135, Train Acc: 71.88%, Val Loss: 0.9066, Val Acc: 61.53%, Time: 0:01:01 *\n",
      "Save model!\n",
      "Iter:     50, Train Loss: 0.8145, Train Acc: 50.00%, Val Loss: 0.7461, Val Acc: 64.33%, Time: 0:01:15 *\n",
      "Iter:     60, Train Loss: 0.5451, Train Acc: 78.12%, Val Loss: 0.6963, Val Acc: 63.67%, Time: 0:01:28 \n",
      "Save model!\n",
      "Iter:     70, Train Loss: 0.6769, Train Acc: 60.94%, Val Loss: 0.6892, Val Acc: 64.87%, Time: 0:01:42 *\n",
      "Iter:     80, Train Loss: 0.5723, Train Acc: 67.19%, Val Loss: 0.6839, Val Acc: 64.60%, Time: 0:01:56 \n",
      "Save model!\n",
      "Iter:     90, Train Loss: 0.6523, Train Acc: 64.06%, Val Loss: 0.6713, Val Acc: 65.07%, Time: 0:02:10 *\n",
      "Save model!\n",
      "Iter:    100, Train Loss: 0.6052, Train Acc: 64.06%, Val Loss: 0.6567, Val Acc: 65.27%, Time: 0:02:24 *\n",
      "Save model!\n",
      "Iter:    110, Train Loss: 0.5331, Train Acc: 76.56%, Val Loss: 0.6503, Val Acc: 65.60%, Time: 0:02:41 *\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 800)\n",
      "(1500, 800)\n",
      "(13500, 3)\n",
      "(1500, 3)\n",
      "Training and evaluating...\n",
      "Epoch: 1\n",
      "Save model!\n",
      "Iter:      0, Train Loss:  1.1, Train Acc: 28.12%, Val Loss: 1.099, Val Acc: 32.93%, Time: 0:00:05 *\n",
      "Save model!\n",
      "Iter:     10, Train Loss: 1.106, Train Acc: 39.06%, Val Loss: 1.095, Val Acc: 55.00%, Time: 0:00:21 *\n",
      "Iter:     20, Train Loss: 1.092, Train Acc: 39.06%, Val Loss: 1.089, Val Acc: 49.80%, Time: 0:00:37 \n",
      "Save model!\n",
      "Iter:     30, Train Loss: 1.064, Train Acc: 70.31%, Val Loss: 1.066, Val Acc: 61.87%, Time: 0:00:54 *\n",
      "Iter:     40, Train Loss: 1.008, Train Acc: 57.81%, Val Loss: 0.9917, Val Acc: 60.80%, Time: 0:01:10 \n",
      "Save model!\n",
      "Iter:     50, Train Loss: 0.8099, Train Acc: 64.06%, Val Loss: 0.8182, Val Acc: 63.47%, Time: 0:01:23 *\n",
      "Iter:     60, Train Loss: 0.653, Train Acc: 68.75%, Val Loss: 0.696, Val Acc: 60.27%, Time: 0:01:37 \n",
      "Save model!\n",
      "Iter:     70, Train Loss: 0.7492, Train Acc: 53.12%, Val Loss: 0.6561, Val Acc: 64.07%, Time: 0:01:50 *\n",
      "Iter:     80, Train Loss: 0.6286, Train Acc: 67.19%, Val Loss: 0.6484, Val Acc: 62.80%, Time: 0:02:06 \n",
      "Save model!\n",
      "Iter:     90, Train Loss: 0.6926, Train Acc: 68.75%, Val Loss: 0.6352, Val Acc: 66.93%, Time: 0:02:20 *\n",
      "Iter:    100, Train Loss: 0.5725, Train Acc: 73.44%, Val Loss: 0.6246, Val Acc: 66.87%, Time: 0:02:33 \n",
      "Save model!\n",
      "Iter:    110, Train Loss: 0.6231, Train Acc: 75.00%, Val Loss: 0.6227, Val Acc: 67.67%, Time: 0:02:46 *\n",
      "Iter:    120, Train Loss: 0.6122, Train Acc: 62.50%, Val Loss: 0.6156, Val Acc: 67.53%, Time: 0:03:00 \n",
      "Save model!\n",
      "Iter:    130, Train Loss: 0.582, Train Acc: 70.31%, Val Loss: 0.6001, Val Acc: 69.33%, Time: 0:03:15 *\n",
      "Iter:    140, Train Loss: 0.6015, Train Acc: 64.06%, Val Loss: 0.5995, Val Acc: 67.67%, Time: 0:03:33 \n",
      "Iter:    150, Train Loss: 0.538, Train Acc: 68.75%, Val Loss: 0.5956, Val Acc: 68.93%, Time: 0:03:47 \n",
      "Iter:    160, Train Loss: 0.581, Train Acc: 75.00%, Val Loss: 0.597, Val Acc: 69.33%, Time: 0:04:04 \n",
      "Save model!\n",
      "Iter:    170, Train Loss: 0.6495, Train Acc: 68.75%, Val Loss: 0.5919, Val Acc: 69.60%, Time: 0:04:19 *\n",
      "Save model!\n",
      "Iter:    180, Train Loss: 0.5392, Train Acc: 78.12%, Val Loss: 0.5842, Val Acc: 69.73%, Time: 0:04:36 *\n",
      "Save model!\n",
      "Iter:    190, Train Loss: 0.563, Train Acc: 73.44%, Val Loss: 0.5855, Val Acc: 70.93%, Time: 0:04:53 *\n",
      "Save model!\n",
      "Iter:    200, Train Loss: 0.5539, Train Acc: 68.75%, Val Loss: 0.5774, Val Acc: 71.07%, Time: 0:05:08 *\n",
      "Iter:    210, Train Loss: 0.5704, Train Acc: 63.33%, Val Loss: 0.5762, Val Acc: 70.80%, Time: 0:05:24 \n",
      "Epoch: 2\n",
      "Iter:    220, Train Loss: 0.5965, Train Acc: 67.19%, Val Loss: 0.6028, Val Acc: 70.00%, Time: 0:05:39 \n",
      "Iter:    230, Train Loss: 0.485, Train Acc: 76.56%, Val Loss: 0.581, Val Acc: 69.60%, Time: 0:05:54 \n",
      "Save model!\n",
      "Iter:    240, Train Loss: 0.5876, Train Acc: 68.75%, Val Loss: 0.5682, Val Acc: 71.73%, Time: 0:06:07 *\n",
      "Save model!\n",
      "Iter:    250, Train Loss: 0.479, Train Acc: 81.25%, Val Loss: 0.5641, Val Acc: 72.73%, Time: 0:06:22 *\n",
      "Iter:    260, Train Loss: 0.4041, Train Acc: 82.81%, Val Loss: 0.5659, Val Acc: 71.60%, Time: 0:06:38 \n",
      "Save model!\n",
      "Iter:    270, Train Loss: 0.6751, Train Acc: 71.88%, Val Loss: 0.5686, Val Acc: 72.80%, Time: 0:06:52 *\n",
      "Iter:    280, Train Loss: 0.5275, Train Acc: 76.56%, Val Loss: 0.585, Val Acc: 70.87%, Time: 0:07:07 \n",
      "Iter:    290, Train Loss: 0.5953, Train Acc: 79.69%, Val Loss: 0.5881, Val Acc: 72.60%, Time: 0:07:21 \n",
      "Iter:    300, Train Loss: 0.5426, Train Acc: 76.56%, Val Loss: 0.5661, Val Acc: 72.73%, Time: 0:07:34 \n",
      "Save model!\n",
      "Iter:    310, Train Loss: 0.491, Train Acc: 79.69%, Val Loss: 0.5417, Val Acc: 73.53%, Time: 0:07:47 *\n",
      "Save model!\n",
      "Iter:    320, Train Loss: 0.4044, Train Acc: 79.69%, Val Loss: 0.5392, Val Acc: 74.47%, Time: 0:08:01 *\n",
      "Iter:    330, Train Loss: 0.505, Train Acc: 71.88%, Val Loss: 0.5364, Val Acc: 73.73%, Time: 0:08:14 \n",
      "Iter:    340, Train Loss: 0.5039, Train Acc: 78.12%, Val Loss: 0.5394, Val Acc: 73.67%, Time: 0:08:28 \n",
      "Iter:    350, Train Loss: 0.5276, Train Acc: 76.56%, Val Loss: 0.5348, Val Acc: 73.53%, Time: 0:08:41 \n",
      "Iter:    360, Train Loss: 0.484, Train Acc: 79.69%, Val Loss: 0.5287, Val Acc: 74.13%, Time: 0:08:54 \n",
      "Save model!\n",
      "Iter:    370, Train Loss: 0.569, Train Acc: 79.69%, Val Loss: 0.5283, Val Acc: 74.87%, Time: 0:09:07 *\n",
      "Iter:    380, Train Loss: 0.5939, Train Acc: 70.31%, Val Loss: 0.5288, Val Acc: 74.27%, Time: 0:09:20 \n",
      "Iter:    390, Train Loss: 0.3828, Train Acc: 82.81%, Val Loss: 0.537, Val Acc: 74.33%, Time: 0:09:33 \n",
      "Iter:    400, Train Loss: 0.5566, Train Acc: 78.12%, Val Loss: 0.5494, Val Acc: 74.20%, Time: 0:09:46 \n",
      "Iter:    410, Train Loss: 0.5473, Train Acc: 64.06%, Val Loss: 0.5435, Val Acc: 74.27%, Time: 0:09:59 \n",
      "Iter:    420, Train Loss: 0.3503, Train Acc: 84.38%, Val Loss: 0.5309, Val Acc: 73.87%, Time: 0:10:11 \n",
      "Epoch: 3\n",
      "Iter:    430, Train Loss: 0.4734, Train Acc: 79.69%, Val Loss: 0.5383, Val Acc: 74.40%, Time: 0:10:25 \n",
      "Save model!\n",
      "Iter:    440, Train Loss: 0.4151, Train Acc: 79.69%, Val Loss: 0.5418, Val Acc: 75.40%, Time: 0:10:38 *\n",
      "Iter:    450, Train Loss: 0.2754, Train Acc: 89.06%, Val Loss: 0.5494, Val Acc: 74.40%, Time: 0:10:52 \n",
      "Iter:    460, Train Loss: 0.3131, Train Acc: 89.06%, Val Loss: 0.5617, Val Acc: 75.13%, Time: 0:11:05 \n",
      "Iter:    470, Train Loss: 0.2135, Train Acc: 93.75%, Val Loss: 0.5556, Val Acc: 74.20%, Time: 0:11:18 \n",
      "Iter:    480, Train Loss: 0.4474, Train Acc: 79.69%, Val Loss: 0.5479, Val Acc: 74.60%, Time: 0:11:30 \n",
      "Save model!\n",
      "Iter:    490, Train Loss: 0.3284, Train Acc: 89.06%, Val Loss: 0.5326, Val Acc: 75.60%, Time: 0:11:43 *\n",
      "Iter:    500, Train Loss: 0.2498, Train Acc: 90.62%, Val Loss: 0.5371, Val Acc: 75.13%, Time: 0:11:57 \n",
      "Iter:    510, Train Loss: 0.2682, Train Acc: 85.94%, Val Loss: 0.5817, Val Acc: 74.60%, Time: 0:12:10 \n",
      "Iter:    520, Train Loss: 0.2668, Train Acc: 90.62%, Val Loss: 0.5654, Val Acc: 74.87%, Time: 0:12:23 \n",
      "Iter:    530, Train Loss: 0.3635, Train Acc: 85.94%, Val Loss: 0.5522, Val Acc: 74.27%, Time: 0:12:36 \n",
      "Iter:    540, Train Loss: 0.3081, Train Acc: 87.50%, Val Loss: 0.5583, Val Acc: 75.20%, Time: 0:12:48 \n",
      "Iter:    550, Train Loss: 0.288, Train Acc: 89.06%, Val Loss: 0.5618, Val Acc: 73.87%, Time: 0:13:02 \n",
      "Iter:    560, Train Loss: 0.3152, Train Acc: 87.50%, Val Loss: 0.5559, Val Acc: 74.60%, Time: 0:13:14 \n",
      "Iter:    570, Train Loss: 0.3899, Train Acc: 87.50%, Val Loss: 0.5513, Val Acc: 73.67%, Time: 0:13:28 \n",
      "Iter:    580, Train Loss: 0.3268, Train Acc: 84.38%, Val Loss: 0.5352, Val Acc: 74.93%, Time: 0:13:40 \n",
      "Iter:    590, Train Loss: 0.3047, Train Acc: 90.62%, Val Loss: 0.5536, Val Acc: 74.47%, Time: 0:13:53 \n",
      "Iter:    600, Train Loss: 0.2824, Train Acc: 87.50%, Val Loss: 0.5522, Val Acc: 75.27%, Time: 0:14:06 \n",
      "Iter:    610, Train Loss: 0.402, Train Acc: 87.50%, Val Loss: 0.5671, Val Acc: 75.20%, Time: 0:14:20 \n",
      "Iter:    620, Train Loss: 0.3959, Train Acc: 82.81%, Val Loss: 0.5399, Val Acc: 75.33%, Time: 0:14:32 \n",
      "Save model!\n",
      "Iter:    630, Train Loss: 0.3387, Train Acc: 85.94%, Val Loss: 0.5424, Val Acc: 76.00%, Time: 0:14:45 *\n",
      "Epoch: 4\n",
      "Save model!\n",
      "Iter:    640, Train Loss: 0.2096, Train Acc: 92.19%, Val Loss: 0.5634, Val Acc: 76.60%, Time: 0:14:59 *\n",
      "Iter:    650, Train Loss: 0.112, Train Acc: 95.31%, Val Loss: 0.5732, Val Acc: 75.60%, Time: 0:15:12 \n",
      "Iter:    660, Train Loss: 0.1471, Train Acc: 95.31%, Val Loss: 0.6162, Val Acc: 75.47%, Time: 0:15:25 \n",
      "Iter:    670, Train Loss: 0.1241, Train Acc: 95.31%, Val Loss: 0.6176, Val Acc: 75.93%, Time: 0:15:38 \n",
      "Iter:    680, Train Loss: 0.1524, Train Acc: 93.75%, Val Loss: 0.6317, Val Acc: 75.93%, Time: 0:15:51 \n",
      "Iter:    690, Train Loss: 0.1318, Train Acc: 95.31%, Val Loss: 0.6448, Val Acc: 76.13%, Time: 0:16:06 \n",
      "Iter:    700, Train Loss: 0.2158, Train Acc: 92.19%, Val Loss: 0.6488, Val Acc: 75.93%, Time: 0:16:20 \n",
      "Iter:    710, Train Loss: 0.2859, Train Acc: 89.06%, Val Loss: 0.6631, Val Acc: 74.67%, Time: 0:16:33 \n",
      "Iter:    720, Train Loss: 0.2298, Train Acc: 92.19%, Val Loss: 0.6416, Val Acc: 75.33%, Time: 0:16:45 \n",
      "Iter:    730, Train Loss: 0.2281, Train Acc: 90.62%, Val Loss: 0.6331, Val Acc: 76.13%, Time: 0:16:58 \n",
      "Iter:    740, Train Loss: 0.2226, Train Acc: 92.19%, Val Loss: 0.6298, Val Acc: 76.13%, Time: 0:17:10 \n",
      "Iter:    750, Train Loss: 0.2726, Train Acc: 87.50%, Val Loss: 0.6272, Val Acc: 75.60%, Time: 0:17:23 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    760, Train Loss: 0.1078, Train Acc: 98.44%, Val Loss: 0.6224, Val Acc: 75.80%, Time: 0:17:35 \n",
      "Iter:    770, Train Loss: 0.1936, Train Acc: 93.75%, Val Loss: 0.6297, Val Acc: 75.87%, Time: 0:17:48 \n",
      "Iter:    780, Train Loss: 0.2191, Train Acc: 92.19%, Val Loss: 0.6463, Val Acc: 75.40%, Time: 0:18:01 \n",
      "Iter:    790, Train Loss: 0.3484, Train Acc: 85.94%, Val Loss: 0.6455, Val Acc: 74.80%, Time: 0:18:14 \n",
      "Iter:    800, Train Loss: 0.3127, Train Acc: 92.19%, Val Loss: 0.6338, Val Acc: 75.93%, Time: 0:18:28 \n",
      "Iter:    810, Train Loss: 0.1011, Train Acc: 98.44%, Val Loss: 0.6459, Val Acc: 75.73%, Time: 0:18:40 \n",
      "Iter:    820, Train Loss: 0.1799, Train Acc: 93.75%, Val Loss: 0.6317, Val Acc: 76.13%, Time: 0:18:53 \n",
      "Iter:    830, Train Loss: 0.2708, Train Acc: 85.94%, Val Loss: 0.6325, Val Acc: 75.13%, Time: 0:19:05 \n",
      "Iter:    840, Train Loss: 0.1718, Train Acc: 92.19%, Val Loss: 0.6083, Val Acc: 75.73%, Time: 0:19:19 \n",
      "Epoch: 5\n",
      "Iter:    850, Train Loss: 0.09633, Train Acc: 95.31%, Val Loss: 0.6253, Val Acc: 75.40%, Time: 0:19:31 \n",
      "Iter:    860, Train Loss: 0.04406, Train Acc: 100.00%, Val Loss: 0.6553, Val Acc: 75.20%, Time: 0:19:44 \n",
      "Iter:    870, Train Loss: 0.04573, Train Acc: 100.00%, Val Loss: 0.7003, Val Acc: 74.87%, Time: 0:19:56 \n",
      "Iter:    880, Train Loss: 0.08813, Train Acc: 96.88%, Val Loss: 0.7208, Val Acc: 75.20%, Time: 0:20:09 \n",
      "Iter:    890, Train Loss: 0.1232, Train Acc: 95.31%, Val Loss: 0.7296, Val Acc: 75.60%, Time: 0:20:22 \n",
      "Iter:    900, Train Loss: 0.2394, Train Acc: 95.31%, Val Loss: 0.7391, Val Acc: 75.13%, Time: 0:20:34 \n",
      "Iter:    910, Train Loss: 0.1073, Train Acc: 96.88%, Val Loss: 0.7267, Val Acc: 75.40%, Time: 0:20:47 \n",
      "Iter:    920, Train Loss: 0.1002, Train Acc: 95.31%, Val Loss: 0.7458, Val Acc: 75.07%, Time: 0:20:59 \n",
      "Iter:    930, Train Loss: 0.0908, Train Acc: 95.31%, Val Loss: 0.7391, Val Acc: 75.60%, Time: 0:21:12 \n",
      "Iter:    940, Train Loss: 0.04702, Train Acc: 98.44%, Val Loss: 0.7604, Val Acc: 75.53%, Time: 0:21:27 \n",
      "Iter:    950, Train Loss: 0.0578, Train Acc: 98.44%, Val Loss: 0.7689, Val Acc: 75.53%, Time: 0:21:42 \n",
      "Iter:    960, Train Loss: 0.1009, Train Acc: 96.88%, Val Loss: 0.7542, Val Acc: 75.27%, Time: 0:21:57 \n",
      "Iter:    970, Train Loss: 0.1296, Train Acc: 95.31%, Val Loss: 0.7602, Val Acc: 75.53%, Time: 0:22:12 \n",
      "Iter:    980, Train Loss: 0.1027, Train Acc: 95.31%, Val Loss: 0.7588, Val Acc: 75.33%, Time: 0:22:27 \n",
      "Iter:    990, Train Loss: 0.07723, Train Acc: 96.88%, Val Loss: 0.7531, Val Acc: 75.67%, Time: 0:22:41 \n",
      "Iter:   1000, Train Loss: 0.161, Train Acc: 93.75%, Val Loss: 0.7376, Val Acc: 75.07%, Time: 0:22:54 \n",
      "Iter:   1010, Train Loss: 0.1195, Train Acc: 93.75%, Val Loss: 0.7228, Val Acc: 74.60%, Time: 0:23:06 \n",
      "Iter:   1020, Train Loss: 0.1327, Train Acc: 93.75%, Val Loss: 0.74, Val Acc: 74.60%, Time: 0:23:19 \n",
      "Iter:   1030, Train Loss: 0.09667, Train Acc: 95.31%, Val Loss: 0.7297, Val Acc: 74.47%, Time: 0:23:33 \n",
      "Iter:   1040, Train Loss: 0.128, Train Acc: 96.88%, Val Loss: 0.7516, Val Acc: 74.47%, Time: 0:23:47 \n",
      "Iter:   1050, Train Loss: 0.2346, Train Acc: 92.19%, Val Loss: 0.7643, Val Acc: 74.73%, Time: 0:23:59 \n",
      "Epoch: 6\n",
      "Iter:   1060, Train Loss: 0.02909, Train Acc: 100.00%, Val Loss: 0.74, Val Acc: 75.00%, Time: 0:24:12 \n",
      "Iter:   1070, Train Loss: 0.05961, Train Acc: 96.88%, Val Loss: 0.7612, Val Acc: 75.20%, Time: 0:24:25 \n",
      "Iter:   1080, Train Loss: 0.03206, Train Acc: 100.00%, Val Loss: 0.7906, Val Acc: 74.87%, Time: 0:24:37 \n",
      "Iter:   1090, Train Loss: 0.04795, Train Acc: 98.44%, Val Loss: 0.8851, Val Acc: 73.80%, Time: 0:24:50 \n",
      "Iter:   1100, Train Loss: 0.1167, Train Acc: 93.75%, Val Loss: 0.8969, Val Acc: 73.80%, Time: 0:25:03 \n",
      "Iter:   1110, Train Loss: 0.07389, Train Acc: 95.31%, Val Loss: 0.8285, Val Acc: 74.20%, Time: 0:25:15 \n",
      "Iter:   1120, Train Loss: 0.1405, Train Acc: 95.31%, Val Loss: 0.8381, Val Acc: 75.47%, Time: 0:25:29 \n",
      "Iter:   1130, Train Loss: 0.09618, Train Acc: 98.44%, Val Loss: 0.8015, Val Acc: 76.27%, Time: 0:25:43 \n",
      "Iter:   1140, Train Loss: 0.03911, Train Acc: 100.00%, Val Loss: 0.8018, Val Acc: 75.93%, Time: 0:25:58 \n",
      "Iter:   1150, Train Loss: 0.04828, Train Acc: 98.44%, Val Loss: 0.8163, Val Acc: 75.93%, Time: 0:26:14 \n",
      "Iter:   1160, Train Loss: 0.2679, Train Acc: 90.62%, Val Loss: 0.7978, Val Acc: 75.73%, Time: 0:26:29 \n",
      "Iter:   1170, Train Loss: 0.02466, Train Acc: 100.00%, Val Loss: 0.7883, Val Acc: 76.07%, Time: 0:26:43 \n",
      "Iter:   1180, Train Loss: 0.09853, Train Acc: 96.88%, Val Loss: 0.7879, Val Acc: 75.60%, Time: 0:26:58 \n",
      "Iter:   1190, Train Loss: 0.2185, Train Acc: 92.19%, Val Loss: 0.8454, Val Acc: 74.73%, Time: 0:27:13 \n",
      "Iter:   1200, Train Loss: 0.16, Train Acc: 96.88%, Val Loss: 0.8092, Val Acc: 75.53%, Time: 0:27:27 \n",
      "Iter:   1210, Train Loss: 0.09416, Train Acc: 95.31%, Val Loss: 0.7907, Val Acc: 75.20%, Time: 0:27:41 \n",
      "Iter:   1220, Train Loss: 0.1194, Train Acc: 95.31%, Val Loss: 0.7967, Val Acc: 75.20%, Time: 0:27:55 \n",
      "Iter:   1230, Train Loss: 0.07263, Train Acc: 98.44%, Val Loss: 0.7992, Val Acc: 75.13%, Time: 0:28:09 \n",
      "Iter:   1240, Train Loss: 0.09427, Train Acc: 98.44%, Val Loss: 0.8157, Val Acc: 76.07%, Time: 0:28:23 \n",
      "Iter:   1250, Train Loss: 0.1382, Train Acc: 93.75%, Val Loss: 0.8414, Val Acc: 74.40%, Time: 0:28:38 \n",
      "Iter:   1260, Train Loss: 0.0372, Train Acc: 100.00%, Val Loss: 0.8179, Val Acc: 75.00%, Time: 0:28:53 \n",
      "Epoch: 7\n",
      "Iter:   1270, Train Loss: 0.008658, Train Acc: 100.00%, Val Loss: 0.8266, Val Acc: 74.00%, Time: 0:29:08 \n",
      "Iter:   1280, Train Loss: 0.009834, Train Acc: 100.00%, Val Loss: 0.8569, Val Acc: 74.80%, Time: 0:29:23 \n",
      "Iter:   1290, Train Loss: 0.1817, Train Acc: 93.75%, Val Loss: 0.8777, Val Acc: 74.80%, Time: 0:29:37 \n",
      "Iter:   1300, Train Loss: 0.1909, Train Acc: 96.88%, Val Loss: 0.9417, Val Acc: 75.20%, Time: 0:29:52 \n",
      "Iter:   1310, Train Loss: 0.02704, Train Acc: 100.00%, Val Loss: 0.8975, Val Acc: 75.33%, Time: 0:30:06 \n",
      "Iter:   1320, Train Loss: 0.1617, Train Acc: 95.31%, Val Loss: 0.9057, Val Acc: 75.40%, Time: 0:30:21 \n",
      "Iter:   1330, Train Loss: 0.05035, Train Acc: 98.44%, Val Loss: 0.9009, Val Acc: 75.27%, Time: 0:30:35 \n",
      "Iter:   1340, Train Loss: 0.03373, Train Acc: 98.44%, Val Loss: 0.8836, Val Acc: 74.93%, Time: 0:30:49 \n",
      "Iter:   1350, Train Loss: 0.03475, Train Acc: 98.44%, Val Loss: 0.9125, Val Acc: 75.60%, Time: 0:31:03 \n",
      "Iter:   1360, Train Loss: 0.02228, Train Acc: 100.00%, Val Loss: 0.8924, Val Acc: 74.40%, Time: 0:31:17 \n",
      "Iter:   1370, Train Loss: 0.03809, Train Acc: 98.44%, Val Loss: 0.8735, Val Acc: 74.87%, Time: 0:31:31 \n",
      "Iter:   1380, Train Loss: 0.01452, Train Acc: 100.00%, Val Loss: 0.8552, Val Acc: 74.87%, Time: 0:31:45 \n",
      "Iter:   1390, Train Loss: 0.04754, Train Acc: 98.44%, Val Loss: 0.8623, Val Acc: 75.13%, Time: 0:31:59 \n",
      "Iter:   1400, Train Loss: 0.01253, Train Acc: 100.00%, Val Loss: 0.8714, Val Acc: 75.27%, Time: 0:32:13 \n",
      "Iter:   1410, Train Loss: 0.08863, Train Acc: 98.44%, Val Loss: 0.8909, Val Acc: 75.33%, Time: 0:32:27 \n",
      "Iter:   1420, Train Loss: 0.03983, Train Acc: 100.00%, Val Loss: 0.8748, Val Acc: 75.93%, Time: 0:32:40 \n",
      "Iter:   1430, Train Loss: 0.03288, Train Acc: 100.00%, Val Loss: 0.8831, Val Acc: 74.60%, Time: 0:32:53 \n",
      "Iter:   1440, Train Loss: 0.02821, Train Acc: 100.00%, Val Loss: 0.8854, Val Acc: 75.20%, Time: 0:33:07 \n",
      "Iter:   1450, Train Loss: 0.06801, Train Acc: 98.44%, Val Loss: 0.8713, Val Acc: 75.07%, Time: 0:33:20 \n",
      "Iter:   1460, Train Loss: 0.06847, Train Acc: 96.88%, Val Loss: 0.8616, Val Acc: 75.60%, Time: 0:33:34 \n",
      "Iter:   1470, Train Loss: 0.03948, Train Acc: 98.44%, Val Loss: 0.8237, Val Acc: 74.60%, Time: 0:33:47 \n",
      "Epoch: 8\n",
      "Iter:   1480, Train Loss: 0.03497, Train Acc: 100.00%, Val Loss: 0.7936, Val Acc: 75.73%, Time: 0:34:00 \n",
      "Iter:   1490, Train Loss: 0.09668, Train Acc: 98.44%, Val Loss: 0.7925, Val Acc: 75.87%, Time: 0:34:14 \n",
      "Iter:   1500, Train Loss: 0.08199, Train Acc: 98.44%, Val Loss: 0.8558, Val Acc: 75.13%, Time: 0:34:28 \n",
      "Iter:   1510, Train Loss: 0.03433, Train Acc: 98.44%, Val Loss: 0.8475, Val Acc: 75.67%, Time: 0:34:41 \n",
      "Iter:   1520, Train Loss: 0.006073, Train Acc: 100.00%, Val Loss: 0.8789, Val Acc: 75.33%, Time: 0:34:54 \n",
      "Iter:   1530, Train Loss: 0.1022, Train Acc: 96.88%, Val Loss: 0.8811, Val Acc: 76.47%, Time: 0:35:07 \n",
      "Iter:   1540, Train Loss: 0.05887, Train Acc: 98.44%, Val Loss: 0.8713, Val Acc: 75.53%, Time: 0:35:20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1550, Train Loss: 0.0659, Train Acc: 98.44%, Val Loss: 0.891, Val Acc: 75.13%, Time: 0:35:33 \n",
      "Iter:   1560, Train Loss: 0.03365, Train Acc: 98.44%, Val Loss: 0.911, Val Acc: 75.60%, Time: 0:35:47 \n",
      "Iter:   1570, Train Loss: 0.02299, Train Acc: 98.44%, Val Loss: 0.9295, Val Acc: 74.87%, Time: 0:36:00 \n",
      "Iter:   1580, Train Loss: 0.009556, Train Acc: 100.00%, Val Loss: 0.895, Val Acc: 75.80%, Time: 0:36:13 \n",
      "Iter:   1590, Train Loss: 0.05456, Train Acc: 98.44%, Val Loss: 0.8942, Val Acc: 75.73%, Time: 0:36:28 \n",
      "Iter:   1600, Train Loss: 0.05747, Train Acc: 98.44%, Val Loss: 0.8874, Val Acc: 76.40%, Time: 0:36:42 \n",
      "Iter:   1610, Train Loss: 0.07463, Train Acc: 96.88%, Val Loss: 0.8834, Val Acc: 75.47%, Time: 0:36:56 \n",
      "Iter:   1620, Train Loss: 0.01815, Train Acc: 100.00%, Val Loss: 0.8564, Val Acc: 75.60%, Time: 0:37:11 \n",
      "Iter:   1630, Train Loss: 0.1593, Train Acc: 96.88%, Val Loss: 0.8254, Val Acc: 75.47%, Time: 0:37:26 \n",
      "Iter:   1640, Train Loss: 0.09189, Train Acc: 98.44%, Val Loss: 0.825, Val Acc: 75.93%, Time: 0:37:40 \n",
      "No optimization for a long time, auto-stopping...\n"
     ]
    }
   ],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 800)\n",
      "(1500, 800)\n",
      "(13500, 3)\n",
      "(1500, 3)\n",
      "Training and evaluating...\n",
      "Epoch: 1\n",
      "Save model!\n",
      "Iter:      0, Train Loss: 1.097, Train Acc: 42.1875%, Val Loss: 1.099, Val Acc: 32.6000%, Time: 0:00:04 *\n",
      "Save model!\n",
      "Iter:     10, Train Loss: 1.094, Train Acc: 37.5000%, Val Loss: 1.098, Val Acc: 34.0000%, Time: 0:00:18 *\n",
      "Save model!\n",
      "Iter:     20, Train Loss: 1.077, Train Acc: 45.3125%, Val Loss: 1.086, Val Acc: 38.3333%, Time: 0:00:34 *\n",
      "Save model!\n",
      "Iter:     30, Train Loss: 1.061, Train Acc: 56.2500%, Val Loss: 1.058, Val Acc: 61.6000%, Time: 0:00:50 *\n",
      "Iter:     40, Train Loss: 1.013, Train Acc: 46.8750%, Val Loss: 0.975, Val Acc: 59.8000%, Time: 0:01:04 \n",
      "Iter:     50, Train Loss: 0.7824, Train Acc: 67.1875%, Val Loss: 0.8201, Val Acc: 59.1333%, Time: 0:01:17 \n",
      "Iter:     60, Train Loss: 0.7701, Train Acc: 59.3750%, Val Loss: 0.7119, Val Acc: 59.8667%, Time: 0:01:33 \n",
      "Save model!\n",
      "Iter:     70, Train Loss: 0.6987, Train Acc: 64.0625%, Val Loss: 0.6899, Val Acc: 62.4000%, Time: 0:01:47 *\n",
      "Save model!\n",
      "Iter:     80, Train Loss: 0.6103, Train Acc: 64.0625%, Val Loss: 0.6769, Val Acc: 63.9333%, Time: 0:02:00 *\n",
      "Save model!\n",
      "Iter:     90, Train Loss: 0.7388, Train Acc: 68.7500%, Val Loss: 0.6573, Val Acc: 67.2000%, Time: 0:02:14 *\n",
      "Iter:    100, Train Loss: 0.868, Train Acc: 56.2500%, Val Loss: 0.6479, Val Acc: 65.2667%, Time: 0:02:28 \n",
      "Save model!\n",
      "Iter:    110, Train Loss: 0.6928, Train Acc: 68.7500%, Val Loss: 0.6336, Val Acc: 67.5333%, Time: 0:02:41 *\n",
      "Save model!\n",
      "Iter:    120, Train Loss: 0.6537, Train Acc: 62.5000%, Val Loss: 0.6235, Val Acc: 68.8667%, Time: 0:02:55 *\n",
      "Iter:    130, Train Loss: 0.5842, Train Acc: 65.6250%, Val Loss: 0.63, Val Acc: 67.7333%, Time: 0:03:09 \n",
      "Save model!\n",
      "Iter:    140, Train Loss: 0.6563, Train Acc: 68.7500%, Val Loss: 0.6158, Val Acc: 69.2000%, Time: 0:03:24 *\n",
      "Save model!\n",
      "Iter:    150, Train Loss: 0.6587, Train Acc: 68.7500%, Val Loss: 0.6103, Val Acc: 70.2667%, Time: 0:03:37 *\n",
      "Iter:    160, Train Loss: 0.5384, Train Acc: 76.5625%, Val Loss: 0.6018, Val Acc: 70.2667%, Time: 0:03:50 \n",
      "Save model!\n",
      "Iter:    170, Train Loss: 0.6559, Train Acc: 64.0625%, Val Loss: 0.5953, Val Acc: 70.6000%, Time: 0:04:05 *\n",
      "Iter:    180, Train Loss: 0.5743, Train Acc: 70.3125%, Val Loss: 0.5901, Val Acc: 70.5333%, Time: 0:04:18 \n",
      "Iter:    190, Train Loss: 0.4972, Train Acc: 73.4375%, Val Loss: 0.5933, Val Acc: 69.7333%, Time: 0:04:31 \n",
      "Save model!\n",
      "Iter:    200, Train Loss: 0.5262, Train Acc: 75.0000%, Val Loss: 0.5783, Val Acc: 70.6667%, Time: 0:04:44 *\n",
      "Save model!\n",
      "Iter:    210, Train Loss: 0.5114, Train Acc: 76.6667%, Val Loss: 0.5748, Val Acc: 72.0667%, Time: 0:04:58 *\n",
      "Epoch: 2\n",
      "Iter:    220, Train Loss: 0.4141, Train Acc: 81.2500%, Val Loss: 0.5721, Val Acc: 71.6667%, Time: 0:05:12 \n",
      "Iter:    230, Train Loss: 0.5029, Train Acc: 68.7500%, Val Loss: 0.5733, Val Acc: 71.8667%, Time: 0:05:26 \n",
      "Save model!\n",
      "Iter:    240, Train Loss: 0.5427, Train Acc: 70.3125%, Val Loss: 0.5682, Val Acc: 72.2667%, Time: 0:05:39 *\n",
      "Save model!\n",
      "Iter:    250, Train Loss: 0.5351, Train Acc: 79.6875%, Val Loss: 0.5658, Val Acc: 72.3333%, Time: 0:05:53 *\n",
      "Iter:    260, Train Loss: 0.4703, Train Acc: 75.0000%, Val Loss: 0.5638, Val Acc: 71.9333%, Time: 0:06:06 \n",
      "Save model!\n",
      "Iter:    270, Train Loss: 0.7805, Train Acc: 78.1250%, Val Loss: 0.5592, Val Acc: 73.0667%, Time: 0:06:19 *\n",
      "Save model!\n",
      "Iter:    280, Train Loss: 0.4084, Train Acc: 82.8125%, Val Loss: 0.558, Val Acc: 73.4667%, Time: 0:06:33 *\n",
      "Iter:    290, Train Loss: 0.5803, Train Acc: 75.0000%, Val Loss: 0.553, Val Acc: 73.0667%, Time: 0:06:46 \n",
      "Iter:    300, Train Loss: 0.3933, Train Acc: 78.1250%, Val Loss: 0.5595, Val Acc: 72.4667%, Time: 0:06:59 \n",
      "Iter:    310, Train Loss: 0.4404, Train Acc: 76.5625%, Val Loss: 0.5588, Val Acc: 72.6000%, Time: 0:07:12 \n",
      "Iter:    320, Train Loss: 0.6245, Train Acc: 68.7500%, Val Loss: 0.5606, Val Acc: 71.9333%, Time: 0:07:25 \n",
      "Iter:    330, Train Loss: 0.4984, Train Acc: 78.1250%, Val Loss: 0.5746, Val Acc: 72.3333%, Time: 0:07:37 \n",
      "Iter:    340, Train Loss: 0.4508, Train Acc: 81.2500%, Val Loss: 0.5541, Val Acc: 73.4000%, Time: 0:07:50 \n",
      "Save model!\n",
      "Iter:    350, Train Loss: 0.5808, Train Acc: 71.8750%, Val Loss: 0.5449, Val Acc: 74.2000%, Time: 0:08:02 *\n",
      "Save model!\n",
      "Iter:    360, Train Loss: 0.5513, Train Acc: 76.5625%, Val Loss: 0.5395, Val Acc: 75.1333%, Time: 0:08:16 *\n",
      "Iter:    370, Train Loss: 0.4563, Train Acc: 79.6875%, Val Loss: 0.5509, Val Acc: 73.6667%, Time: 0:08:30 \n",
      "Save model!\n",
      "Iter:    380, Train Loss: 0.4165, Train Acc: 82.8125%, Val Loss: 0.5462, Val Acc: 75.6667%, Time: 0:08:43 *\n",
      "Iter:    390, Train Loss: 0.5181, Train Acc: 71.8750%, Val Loss: 0.5285, Val Acc: 74.7333%, Time: 0:08:56 \n",
      "Iter:    400, Train Loss: 0.5597, Train Acc: 71.8750%, Val Loss: 0.5361, Val Acc: 74.2000%, Time: 0:09:09 \n",
      "Iter:    410, Train Loss: 0.5072, Train Acc: 76.5625%, Val Loss: 0.5348, Val Acc: 74.5333%, Time: 0:09:22 \n",
      "Iter:    420, Train Loss: 0.545, Train Acc: 78.1250%, Val Loss: 0.5339, Val Acc: 74.4000%, Time: 0:09:35 \n",
      "Epoch: 3\n",
      "Save model!\n",
      "Iter:    430, Train Loss: 0.3075, Train Acc: 89.0625%, Val Loss: 0.5319, Val Acc: 76.0000%, Time: 0:09:47 *\n",
      "Save model!\n",
      "Iter:    440, Train Loss: 0.2747, Train Acc: 89.0625%, Val Loss: 0.5342, Val Acc: 76.1333%, Time: 0:10:01 *\n",
      "Save model!\n",
      "Iter:    450, Train Loss: 0.233, Train Acc: 92.1875%, Val Loss: 0.5388, Val Acc: 76.1333%, Time: 0:10:15 *\n",
      "Iter:    460, Train Loss: 0.3451, Train Acc: 82.8125%, Val Loss: 0.547, Val Acc: 75.7333%, Time: 0:10:28 \n",
      "Iter:    470, Train Loss: 0.2416, Train Acc: 90.6250%, Val Loss: 0.5641, Val Acc: 75.2000%, Time: 0:10:41 \n",
      "Iter:    480, Train Loss: 0.3821, Train Acc: 90.6250%, Val Loss: 0.5693, Val Acc: 75.2667%, Time: 0:10:54 \n",
      "Iter:    490, Train Loss: 0.3528, Train Acc: 81.2500%, Val Loss: 0.5766, Val Acc: 74.5333%, Time: 0:11:06 \n",
      "Iter:    500, Train Loss: 0.3342, Train Acc: 85.9375%, Val Loss: 0.5483, Val Acc: 75.0667%, Time: 0:11:19 \n",
      "Iter:    510, Train Loss: 0.3689, Train Acc: 87.5000%, Val Loss: 0.5464, Val Acc: 75.2000%, Time: 0:11:31 \n",
      "Save model!\n",
      "Iter:    520, Train Loss: 0.3008, Train Acc: 85.9375%, Val Loss: 0.5427, Val Acc: 76.2000%, Time: 0:11:44 *\n",
      "Save model!\n",
      "Iter:    530, Train Loss: 0.4387, Train Acc: 79.6875%, Val Loss: 0.5545, Val Acc: 76.3333%, Time: 0:11:57 *\n",
      "Save model!\n",
      "Iter:    540, Train Loss: 0.2266, Train Acc: 90.6250%, Val Loss: 0.5435, Val Acc: 77.2000%, Time: 0:12:11 *\n",
      "Iter:    550, Train Loss: 0.385, Train Acc: 84.3750%, Val Loss: 0.5379, Val Acc: 76.4000%, Time: 0:12:24 \n",
      "Save model!\n",
      "Iter:    560, Train Loss: 0.4423, Train Acc: 78.1250%, Val Loss: 0.5341, Val Acc: 77.2667%, Time: 0:12:37 *\n",
      "Iter:    570, Train Loss: 0.2475, Train Acc: 90.6250%, Val Loss: 0.5447, Val Acc: 75.2000%, Time: 0:12:50 \n",
      "Iter:    580, Train Loss: 0.3543, Train Acc: 82.8125%, Val Loss: 0.5569, Val Acc: 75.9333%, Time: 0:13:03 \n",
      "Iter:    590, Train Loss: 0.3658, Train Acc: 85.9375%, Val Loss: 0.5489, Val Acc: 76.0000%, Time: 0:13:17 \n",
      "Iter:    600, Train Loss: 0.4124, Train Acc: 84.3750%, Val Loss: 0.5634, Val Acc: 75.2000%, Time: 0:13:29 \n",
      "Iter:    610, Train Loss: 0.3676, Train Acc: 89.0625%, Val Loss: 0.556, Val Acc: 75.8667%, Time: 0:13:42 \n",
      "Iter:    620, Train Loss: 0.2808, Train Acc: 90.6250%, Val Loss: 0.5483, Val Acc: 76.4000%, Time: 0:13:55 \n",
      "Iter:    630, Train Loss: 0.3733, Train Acc: 84.3750%, Val Loss: 0.5443, Val Acc: 76.3333%, Time: 0:14:07 \n",
      "Epoch: 4\n",
      "Iter:    640, Train Loss: 0.1844, Train Acc: 92.1875%, Val Loss: 0.5557, Val Acc: 74.9333%, Time: 0:14:19 \n",
      "Iter:    650, Train Loss: 0.1746, Train Acc: 95.3125%, Val Loss: 0.5774, Val Acc: 76.2000%, Time: 0:14:32 \n",
      "Iter:    660, Train Loss: 0.1685, Train Acc: 98.4375%, Val Loss: 0.5934, Val Acc: 76.3333%, Time: 0:14:44 \n",
      "Iter:    670, Train Loss: 0.1985, Train Acc: 90.6250%, Val Loss: 0.6175, Val Acc: 76.6667%, Time: 0:14:56 \n",
      "Iter:    680, Train Loss: 0.2337, Train Acc: 89.0625%, Val Loss: 0.6043, Val Acc: 76.4667%, Time: 0:15:09 \n",
      "Iter:    690, Train Loss: 0.285, Train Acc: 89.0625%, Val Loss: 0.6134, Val Acc: 76.0000%, Time: 0:15:21 \n",
      "Iter:    700, Train Loss: 0.1924, Train Acc: 89.0625%, Val Loss: 0.6066, Val Acc: 76.6667%, Time: 0:15:34 \n",
      "Iter:    710, Train Loss: 0.2801, Train Acc: 87.5000%, Val Loss: 0.6293, Val Acc: 75.6000%, Time: 0:15:46 \n",
      "Iter:    720, Train Loss: 0.3109, Train Acc: 93.7500%, Val Loss: 0.6382, Val Acc: 76.2000%, Time: 0:15:59 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model!\n",
      "Iter:    730, Train Loss: 0.2358, Train Acc: 95.3125%, Val Loss: 0.6333, Val Acc: 77.4667%, Time: 0:16:11 *\n",
      "Iter:    740, Train Loss: 0.3518, Train Acc: 87.5000%, Val Loss: 0.6369, Val Acc: 76.4667%, Time: 0:16:25 \n",
      "Iter:    750, Train Loss: 0.3315, Train Acc: 84.3750%, Val Loss: 0.6356, Val Acc: 77.0000%, Time: 0:16:38 \n",
      "Iter:    760, Train Loss: 0.2312, Train Acc: 90.6250%, Val Loss: 0.6393, Val Acc: 77.1333%, Time: 0:16:51 \n",
      "Iter:    770, Train Loss: 0.2917, Train Acc: 90.6250%, Val Loss: 0.6508, Val Acc: 75.2000%, Time: 0:17:03 \n",
      "Iter:    780, Train Loss: 0.1641, Train Acc: 95.3125%, Val Loss: 0.6236, Val Acc: 76.6000%, Time: 0:17:16 \n",
      "Iter:    790, Train Loss: 0.2028, Train Acc: 89.0625%, Val Loss: 0.6346, Val Acc: 75.6000%, Time: 0:17:29 \n",
      "Iter:    800, Train Loss: 0.162, Train Acc: 96.8750%, Val Loss: 0.6188, Val Acc: 76.8667%, Time: 0:17:41 \n",
      "Iter:    810, Train Loss: 0.241, Train Acc: 93.7500%, Val Loss: 0.6383, Val Acc: 75.9333%, Time: 0:17:53 \n",
      "Iter:    820, Train Loss: 0.1591, Train Acc: 93.7500%, Val Loss: 0.6349, Val Acc: 76.8667%, Time: 0:18:06 \n",
      "Iter:    830, Train Loss: 0.2054, Train Acc: 87.5000%, Val Loss: 0.6168, Val Acc: 76.0000%, Time: 0:18:18 \n",
      "Iter:    840, Train Loss: 0.2345, Train Acc: 90.6250%, Val Loss: 0.6259, Val Acc: 76.0667%, Time: 0:18:31 \n",
      "Epoch: 5\n",
      "Iter:    850, Train Loss: 0.05664, Train Acc: 98.4375%, Val Loss: 0.6615, Val Acc: 76.3333%, Time: 0:18:43 \n",
      "Iter:    860, Train Loss: 0.1112, Train Acc: 98.4375%, Val Loss: 0.6773, Val Acc: 76.1333%, Time: 0:18:57 \n",
      "Iter:    870, Train Loss: 0.09628, Train Acc: 98.4375%, Val Loss: 0.6868, Val Acc: 76.2000%, Time: 0:19:09 \n",
      "Iter:    880, Train Loss: 0.06243, Train Acc: 100.0000%, Val Loss: 0.6992, Val Acc: 76.2667%, Time: 0:19:22 \n",
      "Iter:    890, Train Loss: 0.09475, Train Acc: 95.3125%, Val Loss: 0.7314, Val Acc: 76.0667%, Time: 0:19:35 \n",
      "Iter:    900, Train Loss: 0.1713, Train Acc: 95.3125%, Val Loss: 0.7513, Val Acc: 75.3333%, Time: 0:19:47 \n",
      "Iter:    910, Train Loss: 0.08922, Train Acc: 96.8750%, Val Loss: 0.7518, Val Acc: 75.9333%, Time: 0:19:59 \n",
      "Iter:    920, Train Loss: 0.093, Train Acc: 96.8750%, Val Loss: 0.7382, Val Acc: 75.7333%, Time: 0:20:12 \n",
      "Iter:    930, Train Loss: 0.1186, Train Acc: 95.3125%, Val Loss: 0.7332, Val Acc: 75.2667%, Time: 0:20:24 \n",
      "Iter:    940, Train Loss: 0.09, Train Acc: 96.8750%, Val Loss: 0.7268, Val Acc: 76.5333%, Time: 0:20:38 \n",
      "Iter:    950, Train Loss: 0.195, Train Acc: 95.3125%, Val Loss: 0.7033, Val Acc: 75.8667%, Time: 0:20:52 \n",
      "Iter:    960, Train Loss: 0.1206, Train Acc: 95.3125%, Val Loss: 0.6887, Val Acc: 75.8667%, Time: 0:21:06 \n",
      "Iter:    970, Train Loss: 0.1348, Train Acc: 95.3125%, Val Loss: 0.6984, Val Acc: 76.7333%, Time: 0:21:19 \n",
      "Iter:    980, Train Loss: 0.213, Train Acc: 93.7500%, Val Loss: 0.7068, Val Acc: 75.9333%, Time: 0:21:32 \n",
      "Iter:    990, Train Loss: 0.1805, Train Acc: 95.3125%, Val Loss: 0.7209, Val Acc: 74.8000%, Time: 0:21:45 \n",
      "Iter:   1000, Train Loss: 0.09486, Train Acc: 95.3125%, Val Loss: 0.7328, Val Acc: 76.1333%, Time: 0:21:58 \n",
      "Iter:   1010, Train Loss: 0.0951, Train Acc: 98.4375%, Val Loss: 0.7511, Val Acc: 76.4667%, Time: 0:22:12 \n",
      "Iter:   1020, Train Loss: 0.05921, Train Acc: 96.8750%, Val Loss: 0.7459, Val Acc: 76.4667%, Time: 0:22:25 \n",
      "Iter:   1030, Train Loss: 0.1139, Train Acc: 96.8750%, Val Loss: 0.7403, Val Acc: 76.4667%, Time: 0:22:39 \n",
      "Iter:   1040, Train Loss: 0.1676, Train Acc: 95.3125%, Val Loss: 0.7326, Val Acc: 76.3333%, Time: 0:22:52 \n",
      "Iter:   1050, Train Loss: 0.07709, Train Acc: 98.4375%, Val Loss: 0.7184, Val Acc: 76.4667%, Time: 0:23:05 \n",
      "Epoch: 6\n",
      "Iter:   1060, Train Loss: 0.03826, Train Acc: 98.4375%, Val Loss: 0.7195, Val Acc: 76.8667%, Time: 0:23:18 \n",
      "Iter:   1070, Train Loss: 0.04593, Train Acc: 98.4375%, Val Loss: 0.7572, Val Acc: 76.3333%, Time: 0:23:31 \n",
      "Iter:   1080, Train Loss: 0.04029, Train Acc: 98.4375%, Val Loss: 0.769, Val Acc: 76.4000%, Time: 0:23:43 \n",
      "Iter:   1090, Train Loss: 0.05109, Train Acc: 98.4375%, Val Loss: 0.7918, Val Acc: 76.1333%, Time: 0:23:56 \n",
      "Iter:   1100, Train Loss: 0.06097, Train Acc: 96.8750%, Val Loss: 0.8012, Val Acc: 76.3333%, Time: 0:24:08 \n",
      "Iter:   1110, Train Loss: 0.06985, Train Acc: 98.4375%, Val Loss: 0.7951, Val Acc: 76.2667%, Time: 0:24:21 \n",
      "Iter:   1120, Train Loss: 0.1301, Train Acc: 96.8750%, Val Loss: 0.82, Val Acc: 75.6000%, Time: 0:24:34 \n",
      "Iter:   1130, Train Loss: 0.02156, Train Acc: 100.0000%, Val Loss: 0.8192, Val Acc: 76.0667%, Time: 0:24:46 \n",
      "Iter:   1140, Train Loss: 0.06753, Train Acc: 98.4375%, Val Loss: 0.8057, Val Acc: 76.3333%, Time: 0:24:58 \n",
      "Iter:   1150, Train Loss: 0.07588, Train Acc: 98.4375%, Val Loss: 0.7969, Val Acc: 76.8667%, Time: 0:25:11 \n",
      "Iter:   1160, Train Loss: 0.1116, Train Acc: 96.8750%, Val Loss: 0.8188, Val Acc: 76.4000%, Time: 0:25:24 \n",
      "Iter:   1170, Train Loss: 0.08003, Train Acc: 98.4375%, Val Loss: 0.8122, Val Acc: 76.0667%, Time: 0:25:36 \n",
      "Iter:   1180, Train Loss: 0.01779, Train Acc: 100.0000%, Val Loss: 0.7981, Val Acc: 76.7333%, Time: 0:25:49 \n",
      "Iter:   1190, Train Loss: 0.1797, Train Acc: 92.1875%, Val Loss: 0.8209, Val Acc: 76.6667%, Time: 0:26:01 \n",
      "Iter:   1200, Train Loss: 0.09272, Train Acc: 98.4375%, Val Loss: 0.7741, Val Acc: 76.2667%, Time: 0:26:13 \n",
      "Iter:   1210, Train Loss: 0.1562, Train Acc: 96.8750%, Val Loss: 0.7996, Val Acc: 75.6000%, Time: 0:26:26 \n",
      "Iter:   1220, Train Loss: 0.1058, Train Acc: 96.8750%, Val Loss: 0.7764, Val Acc: 76.3333%, Time: 0:26:38 \n",
      "Iter:   1230, Train Loss: 0.077, Train Acc: 96.8750%, Val Loss: 0.7939, Val Acc: 75.9333%, Time: 0:26:50 \n",
      "Iter:   1240, Train Loss: 0.0617, Train Acc: 98.4375%, Val Loss: 0.7845, Val Acc: 76.4667%, Time: 0:27:03 \n",
      "Iter:   1250, Train Loss: 0.3976, Train Acc: 90.6250%, Val Loss: 0.8377, Val Acc: 75.4000%, Time: 0:27:15 \n",
      "Iter:   1260, Train Loss: 0.02464, Train Acc: 100.0000%, Val Loss: 0.7708, Val Acc: 76.0000%, Time: 0:27:28 \n",
      "Epoch: 7\n",
      "Iter:   1270, Train Loss: 0.09262, Train Acc: 96.8750%, Val Loss: 0.7657, Val Acc: 75.1333%, Time: 0:27:43 \n",
      "Iter:   1280, Train Loss: 0.07774, Train Acc: 98.4375%, Val Loss: 0.7593, Val Acc: 75.8667%, Time: 0:27:58 \n",
      "Iter:   1290, Train Loss: 0.0138, Train Acc: 100.0000%, Val Loss: 0.8002, Val Acc: 76.1333%, Time: 0:28:13 \n",
      "Iter:   1300, Train Loss: 0.112, Train Acc: 96.8750%, Val Loss: 0.8226, Val Acc: 75.6000%, Time: 0:28:28 \n",
      "Iter:   1310, Train Loss: 0.04413, Train Acc: 96.8750%, Val Loss: 0.8432, Val Acc: 75.2667%, Time: 0:28:43 \n",
      "Iter:   1320, Train Loss: 0.031, Train Acc: 98.4375%, Val Loss: 0.8753, Val Acc: 75.5333%, Time: 0:28:59 \n",
      "Iter:   1330, Train Loss: 0.04404, Train Acc: 98.4375%, Val Loss: 0.8802, Val Acc: 75.0000%, Time: 0:29:14 \n",
      "Iter:   1340, Train Loss: 0.1755, Train Acc: 96.8750%, Val Loss: 0.8352, Val Acc: 75.0000%, Time: 0:29:29 \n",
      "Iter:   1350, Train Loss: 0.07329, Train Acc: 98.4375%, Val Loss: 0.8353, Val Acc: 75.0667%, Time: 0:29:44 \n",
      "Iter:   1360, Train Loss: 0.05493, Train Acc: 98.4375%, Val Loss: 0.8309, Val Acc: 76.0000%, Time: 0:29:58 \n",
      "Iter:   1370, Train Loss: 0.09387, Train Acc: 96.8750%, Val Loss: 0.8464, Val Acc: 76.8667%, Time: 0:30:10 \n",
      "Iter:   1380, Train Loss: 0.03491, Train Acc: 98.4375%, Val Loss: 0.8356, Val Acc: 75.6000%, Time: 0:30:23 \n",
      "Iter:   1390, Train Loss: 0.09097, Train Acc: 96.8750%, Val Loss: 0.8307, Val Acc: 76.1333%, Time: 0:30:35 \n",
      "Iter:   1400, Train Loss: 0.1062, Train Acc: 96.8750%, Val Loss: 0.8451, Val Acc: 76.4000%, Time: 0:30:48 \n",
      "Iter:   1410, Train Loss: 0.1685, Train Acc: 96.8750%, Val Loss: 0.8211, Val Acc: 76.4667%, Time: 0:31:00 \n",
      "Iter:   1420, Train Loss: 0.03243, Train Acc: 100.0000%, Val Loss: 0.8307, Val Acc: 75.6667%, Time: 0:31:12 \n",
      "Iter:   1430, Train Loss: 0.1188, Train Acc: 96.8750%, Val Loss: 0.8769, Val Acc: 75.4667%, Time: 0:31:26 \n",
      "Iter:   1440, Train Loss: 0.1138, Train Acc: 96.8750%, Val Loss: 0.8621, Val Acc: 75.5333%, Time: 0:31:38 \n",
      "Iter:   1450, Train Loss: 0.01622, Train Acc: 100.0000%, Val Loss: 0.8464, Val Acc: 75.6667%, Time: 0:31:50 \n",
      "Iter:   1460, Train Loss: 0.06283, Train Acc: 98.4375%, Val Loss: 0.8316, Val Acc: 75.7333%, Time: 0:32:03 \n",
      "Iter:   1470, Train Loss: 0.05564, Train Acc: 98.4375%, Val Loss: 0.8752, Val Acc: 74.8667%, Time: 0:32:15 \n",
      "Epoch: 8\n",
      "Iter:   1480, Train Loss: 0.09565, Train Acc: 96.8750%, Val Loss: 0.8772, Val Acc: 74.7333%, Time: 0:32:27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1490, Train Loss: 0.0624, Train Acc: 98.4375%, Val Loss: 0.8605, Val Acc: 75.1333%, Time: 0:32:40 \n",
      "Iter:   1500, Train Loss: 0.07063, Train Acc: 96.8750%, Val Loss: 0.9003, Val Acc: 76.0000%, Time: 0:32:52 \n",
      "Iter:   1510, Train Loss: 0.03114, Train Acc: 98.4375%, Val Loss: 0.9323, Val Acc: 74.1333%, Time: 0:33:04 \n",
      "Iter:   1520, Train Loss: 0.01073, Train Acc: 100.0000%, Val Loss: 0.9003, Val Acc: 75.4667%, Time: 0:33:17 \n",
      "Iter:   1530, Train Loss: 0.02592, Train Acc: 98.4375%, Val Loss: 0.9008, Val Acc: 74.8667%, Time: 0:33:30 \n",
      "Iter:   1540, Train Loss: 0.0152, Train Acc: 100.0000%, Val Loss: 0.9398, Val Acc: 75.4000%, Time: 0:33:42 \n",
      "Iter:   1550, Train Loss: 0.03059, Train Acc: 98.4375%, Val Loss: 0.9336, Val Acc: 75.7333%, Time: 0:33:55 \n",
      "Iter:   1560, Train Loss: 0.05194, Train Acc: 98.4375%, Val Loss: 0.9136, Val Acc: 74.2000%, Time: 0:34:08 \n",
      "Iter:   1570, Train Loss: 0.03241, Train Acc: 100.0000%, Val Loss: 0.9325, Val Acc: 75.3333%, Time: 0:34:21 \n",
      "Iter:   1580, Train Loss: 0.1123, Train Acc: 95.3125%, Val Loss: 0.882, Val Acc: 75.6000%, Time: 0:34:33 \n",
      "Iter:   1590, Train Loss: 0.01945, Train Acc: 100.0000%, Val Loss: 0.8663, Val Acc: 75.2667%, Time: 0:34:46 \n",
      "Iter:   1600, Train Loss: 0.1726, Train Acc: 95.3125%, Val Loss: 0.8713, Val Acc: 74.4000%, Time: 0:34:58 \n",
      "Iter:   1610, Train Loss: 0.1182, Train Acc: 96.8750%, Val Loss: 0.8761, Val Acc: 75.2667%, Time: 0:35:10 \n",
      "Iter:   1620, Train Loss: 0.03414, Train Acc: 100.0000%, Val Loss: 0.8706, Val Acc: 74.7333%, Time: 0:35:23 \n",
      "Iter:   1630, Train Loss: 0.08656, Train Acc: 98.4375%, Val Loss: 0.856, Val Acc: 75.3333%, Time: 0:35:36 \n",
      "Iter:   1640, Train Loss: 0.1377, Train Acc: 95.3125%, Val Loss: 0.8719, Val Acc: 76.8000%, Time: 0:35:48 \n",
      "Iter:   1650, Train Loss: 0.01194, Train Acc: 100.0000%, Val Loss: 0.8715, Val Acc: 76.5333%, Time: 0:36:00 \n",
      "Iter:   1660, Train Loss: 0.09504, Train Acc: 96.8750%, Val Loss: 0.8619, Val Acc: 75.4000%, Time: 0:36:13 \n",
      "Iter:   1670, Train Loss: 0.07264, Train Acc: 96.8750%, Val Loss: 0.8285, Val Acc: 76.7333%, Time: 0:36:26 \n",
      "Iter:   1680, Train Loss: 0.05377, Train Acc: 98.4375%, Val Loss: 0.8608, Val Acc: 75.7333%, Time: 0:36:38 \n",
      "Epoch: 9\n",
      "Iter:   1690, Train Loss: 0.09854, Train Acc: 98.4375%, Val Loss: 0.8456, Val Acc: 74.8667%, Time: 0:36:51 \n",
      "Iter:   1700, Train Loss: 0.102, Train Acc: 96.8750%, Val Loss: 0.8484, Val Acc: 76.2667%, Time: 0:37:04 \n",
      "Iter:   1710, Train Loss: 0.1396, Train Acc: 93.7500%, Val Loss: 0.8646, Val Acc: 76.5333%, Time: 0:37:17 \n",
      "Iter:   1720, Train Loss: 0.07908, Train Acc: 98.4375%, Val Loss: 0.8864, Val Acc: 75.2000%, Time: 0:37:30 \n",
      "Iter:   1730, Train Loss: 0.005663, Train Acc: 100.0000%, Val Loss: 0.9266, Val Acc: 75.8000%, Time: 0:37:42 \n",
      "No optimization for a long time, auto-stopping...\n"
     ]
    }
   ],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(param_saving_path, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "    \n",
    "# data_save = {\"wordToID\": data['wordToID'], \"seq_length\": data['seq_length']}\n",
    "\n",
    "# new_saving_path = \"../data/param-classify-test.dat\"\n",
    "# with open(new_saving_path, 'wb') as f:\n",
    "#     pickle.dump(data_save, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
