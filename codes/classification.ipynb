{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNNConfig(object):\n",
    "    \"\"\"CNN param\"\"\"\n",
    "\n",
    "    embedding_dim = 64  # word vector dimension\n",
    "    seq_length = 800  # sequense length\n",
    "    num_classes = 3  # class number\n",
    "    num_filters = 256  # kernel number\n",
    "    kernel_size = 5  # kernel size\n",
    "    vocab_size = 5000  # vocab size\n",
    "\n",
    "    hidden_dim = 128  # fully connected neuro number\n",
    "\n",
    "    dropout_keep_prob = 0.5  # dropout keeping rate\n",
    "    learning_rate = 1e-3  # learning rate\n",
    "\n",
    "    batch_size = 64  # batch size\n",
    "    num_epochs = 10  # total epoch number\n",
    "\n",
    "    print_per_batch = 10  # output iterations\n",
    "    save_per_batch = 10  # save tensorboard iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"text classification，CNN model\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, self.config.seq_length], name='input_x')\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, self.config.num_classes], name='input_y')\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "        self.cnn()\n",
    "\n",
    "    def cnn(self):\n",
    "        \"\"\"CNN model\"\"\"\n",
    "        # word embedding\n",
    "        with tf.device('/cpu:0'):\n",
    "            embedding = tf.get_variable('embedding', [self.config.vocab_size, self.config.embedding_dim])\n",
    "            embedding_inputs = tf.nn.embedding_lookup(embedding, self.input_x)\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            # CNN layer\n",
    "            conv = tf.layers.conv1d(embedding_inputs, self.config.num_filters, self.config.kernel_size, name='conv')\n",
    "            # global max pooling layer\n",
    "            gmp = tf.reduce_max(conv, reduction_indices=[1], name='gmp')\n",
    "\n",
    "        with tf.name_scope(\"score\"):\n",
    "            # fully connected layer，with dropout and ReLU\n",
    "            fc = tf.layers.dense(gmp, self.config.hidden_dim, name='fc1')\n",
    "            fc = tf.contrib.layers.dropout(fc, self.keep_prob)\n",
    "            fc = tf.nn.relu(fc)\n",
    "\n",
    "            # classifier\n",
    "            self.logits = tf.layers.dense(fc, self.config.num_classes, name='fc2')\n",
    "            self.y_pred_cls = tf.argmax(tf.nn.softmax(self.logits), 1)  # predictor\n",
    "\n",
    "        with tf.name_scope(\"optimize\"):\n",
    "            # loss function，cross entropy\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(cross_entropy)\n",
    "            # optimizor\n",
    "            self.optim = tf.train.AdamOptimizer(learning_rate=self.config.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            # accuracy\n",
    "            correct_pred = tf.equal(tf.argmax(self.input_y, 1), self.y_pred_cls)\n",
    "            self.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/textcnn'\n",
    "save_path = os.path.join(save_dir, 'best_validation')\n",
    "param_saving_path = '../data/param-classify.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x, y, batch_size=64):\n",
    "    \"\"\"generate batchsize data\"\"\"\n",
    "    data_len = len(x)\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuffle = x[indices]\n",
    "    y_shuffle = y[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dif(start_time):\n",
    "    \"\"\"get time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "def feed_data(x_batch, y_batch, keep_prob):\n",
    "    feed_dict = {\n",
    "        model.input_x: x_batch,\n",
    "        model.input_y: y_batch,\n",
    "        model.keep_prob: keep_prob\n",
    "    }\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def evaluate(sess, x_, y_):\n",
    "    \"\"\"evaluate the loss and accuracy\"\"\"\n",
    "    data_len = len(x_)\n",
    "    batch_eval = batch_iter(x_, y_, 128)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    for x_batch, y_batch in batch_eval:\n",
    "        batch_len = len(x_batch)\n",
    "        feed_dict = feed_data(x_batch, y_batch, 1.0)\n",
    "        loss, acc = sess.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "        total_loss += loss * batch_len\n",
    "        total_acc += acc * batch_len\n",
    "\n",
    "    return total_loss / data_len, total_acc / data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tensorboard_dir = 'tensorboard/textcnn'\n",
    "    if not os.path.exists(tensorboard_dir):\n",
    "        os.makedirs(tensorboard_dir)\n",
    "\n",
    "    tf.summary.scalar(\"loss\", model.loss)\n",
    "    tf.summary.scalar(\"accuracy\", model.acc)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(tensorboard_dir)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    validation_rate = 0.1\n",
    "    idx = int(x.shape[0] * validation_rate)\n",
    "    x_train = x[idx:]\n",
    "    x_val = x[:idx]\n",
    "    y_train = y[idx:]\n",
    "    y_val = y[:idx]\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_val.shape)\n",
    "    \n",
    "    \n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    writer.add_graph(session.graph)\n",
    "    \n",
    "    print('Training and evaluating...')\n",
    "    start_time = time.time()\n",
    "    total_batch = 0  # total batch number\n",
    "    best_acc_val = 0.0  # best validation accuracy\n",
    "    last_improved = 0  # last improving\n",
    "    require_improvement = 1000  # if not improving after 1000 iterations, end early\n",
    "    \n",
    "    flag = False\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch:', epoch + 1)\n",
    "        batch_train = batch_iter(x_train, y_train, config.batch_size)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            feed_dict = feed_data(x_batch, y_batch, config.dropout_keep_prob)\n",
    "            \n",
    "            if total_batch % config.save_per_batch == 0:\n",
    "                # save to tensorboard scalar\n",
    "                s = session.run(merged_summary, feed_dict=feed_dict)\n",
    "                writer.add_summary(s, total_batch)\n",
    "\n",
    "\n",
    "            if total_batch % config.print_per_batch == 0:\n",
    "                # get the loss and accuracy on training set and validation set\n",
    "                feed_dict[model.keep_prob] = 1.0\n",
    "                loss_train, acc_train = session.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "                loss_val, acc_val = evaluate(session, x_val, y_val)  # todo\n",
    "\n",
    "                if acc_val > best_acc_val:\n",
    "                    # save the best result\n",
    "                    best_acc_val = acc_val\n",
    "                    last_improved = total_batch\n",
    "                    saver.save(sess=session, save_path=save_path)\n",
    "                    print(\"Save model!\")\n",
    "                    improved_str = '*'\n",
    "                else:\n",
    "                    improved_str = ''\n",
    "\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = 'Iter: {0:>6}, Train Loss: {1:>4.4}, Train Acc: {2:>5.2%},' \\\n",
    "                      + ' Val Loss: {3:>4.4}, Val Acc: {4:>5.2%}, Time: {5} {6}'\n",
    "                print(msg.format(total_batch, loss_train, acc_train, loss_val, acc_val, time_dif, improved_str))\n",
    "\n",
    "            session.run(model.optim, feed_dict=feed_dict) \n",
    "            total_batch += 1\n",
    "\n",
    "            if total_batch - last_improved > require_improvement:\n",
    "                # early end\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break \n",
    "        if flag:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "config = TCNNConfig()\n",
    "with open(param_saving_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "print(len(x))\n",
    "P = np.random.permutation(len(x))\n",
    "x = x[P]\n",
    "y = y[P]\n",
    "\n",
    "wordToID = data['wordToID']\n",
    "seq_length = data['seq_length']\n",
    "config.vocab_size = len(wordToID)\n",
    "config.seq_length = seq_length\n",
    "\n",
    "model = TextCNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 800)\n",
      "(1500, 800)\n",
      "(13500, 3)\n",
      "(1500, 3)\n",
      "Training and evaluating...\n",
      "Epoch: 1\n",
      "Save model!\n",
      "Iter:      0, Train Loss:  1.1, Train Acc: 32.81%, Val Loss: 1.098, Val Acc: 35.33%, Time: 0:00:07 *\n",
      "Iter:     10, Train Loss: 1.089, Train Acc: 39.06%, Val Loss: 1.097, Val Acc: 32.40%, Time: 0:00:23 \n",
      "Save model!\n",
      "Iter:     20, Train Loss: 1.076, Train Acc: 59.38%, Val Loss: 1.079, Val Acc: 58.27%, Time: 0:00:40 *\n",
      "Iter:     30, Train Loss: 1.028, Train Acc: 64.06%, Val Loss: 1.031, Val Acc: 57.67%, Time: 0:00:55 \n",
      "Save model!\n",
      "Iter:     40, Train Loss: 0.9044, Train Acc: 67.19%, Val Loss: 0.9084, Val Acc: 63.20%, Time: 0:01:09 *\n",
      "Iter:     50, Train Loss: 0.7553, Train Acc: 64.06%, Val Loss: 0.7621, Val Acc: 60.73%, Time: 0:01:25 \n",
      "Save model!\n",
      "Iter:     60, Train Loss: 0.7358, Train Acc: 59.38%, Val Loss: 0.6763, Val Acc: 65.27%, Time: 0:01:41 *\n",
      "Iter:     70, Train Loss: 0.569, Train Acc: 75.00%, Val Loss: 0.6544, Val Acc: 64.60%, Time: 0:01:56 \n",
      "Save model!\n",
      "Iter:     80, Train Loss: 0.6878, Train Acc: 60.94%, Val Loss: 0.6457, Val Acc: 66.87%, Time: 0:02:12 *\n",
      "Iter:     90, Train Loss: 0.6912, Train Acc: 60.94%, Val Loss: 0.6399, Val Acc: 66.53%, Time: 0:02:29 \n",
      "Save model!\n",
      "Iter:    100, Train Loss: 0.6151, Train Acc: 70.31%, Val Loss: 0.6452, Val Acc: 68.33%, Time: 0:02:47 *\n",
      "Iter:    110, Train Loss: 0.688, Train Acc: 73.44%, Val Loss: 0.6363, Val Acc: 67.33%, Time: 0:03:04 \n",
      "Save model!\n",
      "Iter:    120, Train Loss: 0.646, Train Acc: 70.31%, Val Loss: 0.6176, Val Acc: 70.00%, Time: 0:03:23 *\n",
      "Save model!\n",
      "Iter:    130, Train Loss: 0.54, Train Acc: 71.88%, Val Loss: 0.6112, Val Acc: 71.27%, Time: 0:03:41 *\n",
      "Iter:    140, Train Loss: 0.6395, Train Acc: 68.75%, Val Loss: 0.6091, Val Acc: 70.20%, Time: 0:03:59 \n",
      "Iter:    150, Train Loss: 0.5027, Train Acc: 76.56%, Val Loss: 0.6046, Val Acc: 70.73%, Time: 0:04:22 \n",
      "Save model!\n",
      "Iter:    160, Train Loss: 0.6495, Train Acc: 60.94%, Val Loss: 0.5946, Val Acc: 71.93%, Time: 0:04:41 *\n",
      "Save model!\n",
      "Iter:    170, Train Loss: 0.6518, Train Acc: 67.19%, Val Loss: 0.5897, Val Acc: 72.80%, Time: 0:04:59 *\n",
      "Iter:    180, Train Loss: 0.6383, Train Acc: 59.38%, Val Loss: 0.5918, Val Acc: 71.67%, Time: 0:05:16 \n",
      "Save model!\n",
      "Iter:    190, Train Loss: 0.5731, Train Acc: 75.00%, Val Loss: 0.5836, Val Acc: 73.40%, Time: 0:05:34 *\n",
      "Iter:    200, Train Loss: 0.7066, Train Acc: 64.06%, Val Loss: 0.5831, Val Acc: 73.33%, Time: 0:05:50 \n",
      "Save model!\n",
      "Iter:    210, Train Loss: 0.5931, Train Acc: 63.33%, Val Loss: 0.5847, Val Acc: 74.27%, Time: 0:06:06 *\n",
      "Epoch: 2\n",
      "Iter:    220, Train Loss: 0.5443, Train Acc: 75.00%, Val Loss: 0.5749, Val Acc: 74.00%, Time: 0:06:21 \n",
      "Iter:    230, Train Loss: 0.4941, Train Acc: 78.12%, Val Loss: 0.5781, Val Acc: 71.40%, Time: 0:06:35 \n",
      "Iter:    240, Train Loss: 0.5046, Train Acc: 76.56%, Val Loss: 0.577, Val Acc: 72.73%, Time: 0:06:49 \n",
      "Iter:    250, Train Loss: 0.5116, Train Acc: 79.69%, Val Loss: 0.5725, Val Acc: 72.80%, Time: 0:07:03 \n",
      "Iter:    260, Train Loss: 0.5357, Train Acc: 71.88%, Val Loss: 0.5934, Val Acc: 72.07%, Time: 0:07:16 \n",
      "Iter:    270, Train Loss: 0.4039, Train Acc: 84.38%, Val Loss: 0.5702, Val Acc: 73.07%, Time: 0:07:30 \n",
      "Iter:    280, Train Loss: 0.4639, Train Acc: 78.12%, Val Loss: 0.5684, Val Acc: 72.47%, Time: 0:07:44 \n",
      "Iter:    290, Train Loss: 0.5982, Train Acc: 78.12%, Val Loss: 0.5945, Val Acc: 72.60%, Time: 0:07:58 \n",
      "Iter:    300, Train Loss: 0.6803, Train Acc: 62.50%, Val Loss: 0.5623, Val Acc: 74.07%, Time: 0:08:12 \n",
      "Iter:    310, Train Loss: 0.426, Train Acc: 81.25%, Val Loss: 0.5693, Val Acc: 71.60%, Time: 0:08:26 \n",
      "Iter:    320, Train Loss: 0.4116, Train Acc: 76.56%, Val Loss: 0.5618, Val Acc: 73.73%, Time: 0:08:39 \n",
      "Iter:    330, Train Loss: 0.5206, Train Acc: 71.88%, Val Loss: 0.5733, Val Acc: 72.93%, Time: 0:08:53 \n",
      "Iter:    340, Train Loss: 0.394, Train Acc: 79.69%, Val Loss: 0.5645, Val Acc: 73.80%, Time: 0:09:06 \n",
      "Iter:    350, Train Loss: 0.5897, Train Acc: 75.00%, Val Loss: 0.5697, Val Acc: 73.07%, Time: 0:09:19 \n",
      "Iter:    360, Train Loss: 0.7164, Train Acc: 70.31%, Val Loss: 0.5621, Val Acc: 73.27%, Time: 0:09:32 \n",
      "Iter:    370, Train Loss: 0.4286, Train Acc: 76.56%, Val Loss: 0.5521, Val Acc: 73.27%, Time: 0:09:44 \n",
      "Save model!\n",
      "Iter:    380, Train Loss: 0.5245, Train Acc: 78.12%, Val Loss: 0.5491, Val Acc: 74.60%, Time: 0:09:57 *\n",
      "Save model!\n",
      "Iter:    390, Train Loss: 0.5696, Train Acc: 70.31%, Val Loss: 0.5433, Val Acc: 74.80%, Time: 0:10:11 *\n",
      "Iter:    400, Train Loss: 0.4613, Train Acc: 81.25%, Val Loss: 0.5716, Val Acc: 73.40%, Time: 0:10:24 \n",
      "Iter:    410, Train Loss: 0.4906, Train Acc: 82.81%, Val Loss: 0.546, Val Acc: 74.13%, Time: 0:10:37 \n",
      "Save model!\n",
      "Iter:    420, Train Loss: 0.4677, Train Acc: 75.00%, Val Loss: 0.5382, Val Acc: 75.47%, Time: 0:10:51 *\n",
      "Epoch: 3\n",
      "Iter:    430, Train Loss: 0.3895, Train Acc: 84.38%, Val Loss: 0.5335, Val Acc: 75.40%, Time: 0:11:04 \n",
      "Save model!\n",
      "Iter:    440, Train Loss: 0.3565, Train Acc: 89.06%, Val Loss: 0.5413, Val Acc: 75.67%, Time: 0:11:18 *\n",
      "Iter:    450, Train Loss: 0.3893, Train Acc: 87.50%, Val Loss: 0.56, Val Acc: 75.13%, Time: 0:11:32 \n",
      "Iter:    460, Train Loss: 0.3575, Train Acc: 82.81%, Val Loss: 0.6099, Val Acc: 73.27%, Time: 0:11:46 \n",
      "Iter:    470, Train Loss: 0.3326, Train Acc: 84.38%, Val Loss: 0.5592, Val Acc: 75.33%, Time: 0:11:59 \n",
      "Iter:    480, Train Loss: 0.3954, Train Acc: 82.81%, Val Loss: 0.5517, Val Acc: 74.67%, Time: 0:12:11 \n",
      "Iter:    490, Train Loss: 0.396, Train Acc: 81.25%, Val Loss: 0.554, Val Acc: 75.33%, Time: 0:12:24 \n",
      "Save model!\n",
      "Iter:    500, Train Loss: 0.2912, Train Acc: 92.19%, Val Loss: 0.5503, Val Acc: 76.47%, Time: 0:12:37 *\n",
      "Iter:    510, Train Loss: 0.3115, Train Acc: 81.25%, Val Loss: 0.5768, Val Acc: 75.33%, Time: 0:12:51 \n",
      "Iter:    520, Train Loss: 0.4069, Train Acc: 85.94%, Val Loss: 0.575, Val Acc: 75.20%, Time: 0:13:05 \n",
      "Iter:    530, Train Loss: 0.3402, Train Acc: 85.94%, Val Loss: 0.5598, Val Acc: 76.07%, Time: 0:13:17 \n",
      "Iter:    540, Train Loss: 0.4761, Train Acc: 76.56%, Val Loss: 0.561, Val Acc: 75.93%, Time: 0:13:30 \n",
      "Iter:    550, Train Loss: 0.2688, Train Acc: 93.75%, Val Loss: 0.5705, Val Acc: 76.27%, Time: 0:13:42 \n",
      "Iter:    560, Train Loss: 0.3864, Train Acc: 87.50%, Val Loss: 0.5768, Val Acc: 75.80%, Time: 0:13:55 \n",
      "Iter:    570, Train Loss: 0.4749, Train Acc: 84.38%, Val Loss: 0.5716, Val Acc: 75.27%, Time: 0:14:07 \n",
      "Iter:    580, Train Loss: 0.3469, Train Acc: 85.94%, Val Loss: 0.5685, Val Acc: 75.20%, Time: 0:14:19 \n",
      "Iter:    590, Train Loss: 0.4288, Train Acc: 75.00%, Val Loss: 0.5678, Val Acc: 75.73%, Time: 0:14:32 \n",
      "Iter:    600, Train Loss: 0.3859, Train Acc: 85.94%, Val Loss: 0.5637, Val Acc: 74.60%, Time: 0:14:44 \n",
      "Iter:    610, Train Loss: 0.3203, Train Acc: 84.38%, Val Loss: 0.5646, Val Acc: 75.73%, Time: 0:14:57 \n",
      "Iter:    620, Train Loss: 0.3314, Train Acc: 85.94%, Val Loss: 0.5641, Val Acc: 76.00%, Time: 0:15:09 \n",
      "Save model!\n",
      "Iter:    630, Train Loss: 0.2587, Train Acc: 89.06%, Val Loss: 0.5577, Val Acc: 76.60%, Time: 0:15:22 *\n",
      "Epoch: 4\n",
      "Iter:    640, Train Loss: 0.2509, Train Acc: 90.62%, Val Loss: 0.5515, Val Acc: 76.07%, Time: 0:15:36 \n",
      "Iter:    650, Train Loss: 0.1844, Train Acc: 95.31%, Val Loss: 0.5882, Val Acc: 75.47%, Time: 0:15:50 \n",
      "Iter:    660, Train Loss: 0.2643, Train Acc: 90.62%, Val Loss: 0.5785, Val Acc: 76.47%, Time: 0:16:03 \n",
      "Save model!\n",
      "Iter:    670, Train Loss: 0.2301, Train Acc: 92.19%, Val Loss: 0.5982, Val Acc: 76.67%, Time: 0:16:15 *\n",
      "Iter:    680, Train Loss: 0.09843, Train Acc: 98.44%, Val Loss: 0.6216, Val Acc: 76.07%, Time: 0:16:29 \n",
      "Iter:    690, Train Loss: 0.3726, Train Acc: 81.25%, Val Loss: 0.6353, Val Acc: 76.20%, Time: 0:16:42 \n",
      "Iter:    700, Train Loss: 0.1715, Train Acc: 95.31%, Val Loss: 0.646, Val Acc: 75.73%, Time: 0:16:55 \n",
      "Iter:    710, Train Loss: 0.2446, Train Acc: 90.62%, Val Loss: 0.6404, Val Acc: 75.80%, Time: 0:17:08 \n",
      "Iter:    720, Train Loss: 0.1619, Train Acc: 93.75%, Val Loss: 0.6864, Val Acc: 75.67%, Time: 0:17:20 \n",
      "Iter:    730, Train Loss: 0.1171, Train Acc: 98.44%, Val Loss: 0.6703, Val Acc: 74.40%, Time: 0:17:32 \n",
      "Iter:    740, Train Loss: 0.2652, Train Acc: 92.19%, Val Loss: 0.6457, Val Acc: 75.47%, Time: 0:17:45 \n",
      "Iter:    750, Train Loss: 0.2149, Train Acc: 92.19%, Val Loss: 0.6466, Val Acc: 75.73%, Time: 0:17:57 \n",
      "Iter:    760, Train Loss: 0.186, Train Acc: 95.31%, Val Loss: 0.664, Val Acc: 74.53%, Time: 0:18:09 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    770, Train Loss: 0.3459, Train Acc: 84.38%, Val Loss: 0.6511, Val Acc: 76.40%, Time: 0:18:22 \n",
      "Iter:    780, Train Loss: 0.2286, Train Acc: 92.19%, Val Loss: 0.6435, Val Acc: 75.67%, Time: 0:18:34 \n",
      "Iter:    790, Train Loss: 0.233, Train Acc: 92.19%, Val Loss: 0.6447, Val Acc: 75.53%, Time: 0:18:47 \n",
      "Iter:    800, Train Loss: 0.2458, Train Acc: 93.75%, Val Loss: 0.6694, Val Acc: 75.07%, Time: 0:18:59 \n",
      "Iter:    810, Train Loss: 0.2958, Train Acc: 87.50%, Val Loss: 0.6558, Val Acc: 75.80%, Time: 0:19:11 \n",
      "Iter:    820, Train Loss: 0.2761, Train Acc: 92.19%, Val Loss: 0.6628, Val Acc: 75.33%, Time: 0:19:23 \n",
      "Iter:    830, Train Loss: 0.2831, Train Acc: 89.06%, Val Loss: 0.6529, Val Acc: 75.47%, Time: 0:19:36 \n",
      "Iter:    840, Train Loss: 0.1485, Train Acc: 93.75%, Val Loss: 0.6333, Val Acc: 76.27%, Time: 0:19:48 \n",
      "Epoch: 5\n",
      "Iter:    850, Train Loss: 0.1546, Train Acc: 95.31%, Val Loss: 0.6429, Val Acc: 75.27%, Time: 0:20:00 \n",
      "Iter:    860, Train Loss: 0.121, Train Acc: 98.44%, Val Loss: 0.6627, Val Acc: 76.33%, Time: 0:20:13 \n",
      "Iter:    870, Train Loss: 0.05332, Train Acc: 98.44%, Val Loss: 0.7017, Val Acc: 75.60%, Time: 0:20:25 \n",
      "Iter:    880, Train Loss: 0.1243, Train Acc: 95.31%, Val Loss: 0.7305, Val Acc: 75.73%, Time: 0:20:38 \n",
      "Iter:    890, Train Loss: 0.09484, Train Acc: 98.44%, Val Loss: 0.7579, Val Acc: 76.00%, Time: 0:20:51 \n",
      "Iter:    900, Train Loss: 0.06351, Train Acc: 98.44%, Val Loss: 0.7627, Val Acc: 75.27%, Time: 0:21:03 \n",
      "Iter:    910, Train Loss: 0.0305, Train Acc: 100.00%, Val Loss: 0.7776, Val Acc: 75.73%, Time: 0:21:15 \n",
      "Iter:    920, Train Loss: 0.07242, Train Acc: 98.44%, Val Loss: 0.7964, Val Acc: 75.00%, Time: 0:21:27 \n",
      "Iter:    930, Train Loss: 0.2429, Train Acc: 92.19%, Val Loss: 0.7886, Val Acc: 75.27%, Time: 0:21:40 \n",
      "Iter:    940, Train Loss: 0.1599, Train Acc: 93.75%, Val Loss: 0.7669, Val Acc: 75.73%, Time: 0:21:52 \n",
      "Iter:    950, Train Loss: 0.08827, Train Acc: 96.88%, Val Loss: 0.7384, Val Acc: 76.33%, Time: 0:22:04 \n",
      "Iter:    960, Train Loss: 0.05359, Train Acc: 98.44%, Val Loss: 0.7455, Val Acc: 76.07%, Time: 0:22:17 \n",
      "Iter:    970, Train Loss: 0.1676, Train Acc: 93.75%, Val Loss: 0.7989, Val Acc: 75.40%, Time: 0:22:29 \n",
      "Iter:    980, Train Loss: 0.05801, Train Acc: 100.00%, Val Loss: 0.7646, Val Acc: 76.27%, Time: 0:22:41 \n",
      "Iter:    990, Train Loss: 0.09436, Train Acc: 98.44%, Val Loss: 0.8185, Val Acc: 74.60%, Time: 0:22:54 \n",
      "Iter:   1000, Train Loss: 0.09776, Train Acc: 98.44%, Val Loss: 0.761, Val Acc: 75.80%, Time: 0:23:06 \n",
      "Iter:   1010, Train Loss: 0.201, Train Acc: 92.19%, Val Loss: 0.7404, Val Acc: 75.60%, Time: 0:23:19 \n",
      "Iter:   1020, Train Loss: 0.2245, Train Acc: 92.19%, Val Loss: 0.7388, Val Acc: 75.00%, Time: 0:23:31 \n",
      "Iter:   1030, Train Loss: 0.2127, Train Acc: 90.62%, Val Loss: 0.7298, Val Acc: 74.87%, Time: 0:23:43 \n",
      "Iter:   1040, Train Loss: 0.2952, Train Acc: 92.19%, Val Loss: 0.7229, Val Acc: 75.53%, Time: 0:23:55 \n",
      "Iter:   1050, Train Loss: 0.1167, Train Acc: 95.31%, Val Loss: 0.7288, Val Acc: 75.33%, Time: 0:24:08 \n",
      "Epoch: 6\n",
      "Iter:   1060, Train Loss: 0.05514, Train Acc: 98.44%, Val Loss: 0.7214, Val Acc: 76.13%, Time: 0:24:20 \n",
      "Iter:   1070, Train Loss: 0.07908, Train Acc: 96.88%, Val Loss: 0.7479, Val Acc: 75.93%, Time: 0:24:32 \n",
      "Iter:   1080, Train Loss: 0.04908, Train Acc: 98.44%, Val Loss: 0.7745, Val Acc: 75.87%, Time: 0:24:45 \n",
      "Iter:   1090, Train Loss: 0.03335, Train Acc: 100.00%, Val Loss: 0.7977, Val Acc: 75.80%, Time: 0:24:57 \n",
      "Iter:   1100, Train Loss: 0.02287, Train Acc: 100.00%, Val Loss: 0.8062, Val Acc: 76.33%, Time: 0:25:10 \n",
      "Iter:   1110, Train Loss: 0.08724, Train Acc: 95.31%, Val Loss: 0.8069, Val Acc: 75.80%, Time: 0:25:22 \n",
      "Iter:   1120, Train Loss: 0.05789, Train Acc: 98.44%, Val Loss: 0.8138, Val Acc: 75.73%, Time: 0:25:35 \n",
      "Iter:   1130, Train Loss: 0.06045, Train Acc: 98.44%, Val Loss: 0.8131, Val Acc: 76.13%, Time: 0:25:47 \n",
      "Iter:   1140, Train Loss: 0.08659, Train Acc: 98.44%, Val Loss: 0.8113, Val Acc: 76.27%, Time: 0:25:59 \n",
      "Iter:   1150, Train Loss: 0.08771, Train Acc: 96.88%, Val Loss: 0.7872, Val Acc: 76.07%, Time: 0:26:12 \n",
      "Iter:   1160, Train Loss: 0.159, Train Acc: 95.31%, Val Loss: 0.79, Val Acc: 76.47%, Time: 0:26:24 \n",
      "Iter:   1170, Train Loss: 0.05766, Train Acc: 98.44%, Val Loss: 0.799, Val Acc: 76.27%, Time: 0:26:36 \n",
      "Iter:   1180, Train Loss: 0.04794, Train Acc: 98.44%, Val Loss: 0.7913, Val Acc: 76.53%, Time: 0:26:49 \n",
      "Iter:   1190, Train Loss: 0.1232, Train Acc: 96.88%, Val Loss: 0.7949, Val Acc: 75.60%, Time: 0:27:02 \n",
      "Iter:   1200, Train Loss: 0.08397, Train Acc: 96.88%, Val Loss: 0.7895, Val Acc: 75.53%, Time: 0:27:14 \n",
      "Iter:   1210, Train Loss: 0.2222, Train Acc: 92.19%, Val Loss: 0.7944, Val Acc: 75.67%, Time: 0:27:26 \n",
      "Iter:   1220, Train Loss: 0.1026, Train Acc: 98.44%, Val Loss: 0.7986, Val Acc: 76.33%, Time: 0:27:39 \n",
      "Iter:   1230, Train Loss: 0.2142, Train Acc: 93.75%, Val Loss: 0.7837, Val Acc: 76.13%, Time: 0:27:51 \n",
      "Iter:   1240, Train Loss: 0.02356, Train Acc: 100.00%, Val Loss: 0.7925, Val Acc: 76.00%, Time: 0:28:03 \n",
      "Iter:   1250, Train Loss: 0.1703, Train Acc: 93.75%, Val Loss: 0.7788, Val Acc: 76.00%, Time: 0:28:16 \n",
      "Iter:   1260, Train Loss: 0.1167, Train Acc: 96.88%, Val Loss: 0.7834, Val Acc: 76.20%, Time: 0:28:28 \n",
      "Epoch: 7\n",
      "Save model!\n",
      "Iter:   1270, Train Loss: 0.1161, Train Acc: 98.44%, Val Loss: 0.7946, Val Acc: 76.73%, Time: 0:28:41 *\n",
      "Iter:   1280, Train Loss: 0.09466, Train Acc: 96.88%, Val Loss: 0.7999, Val Acc: 76.47%, Time: 0:28:55 \n",
      "Iter:   1290, Train Loss: 0.07098, Train Acc: 98.44%, Val Loss: 0.8066, Val Acc: 76.33%, Time: 0:29:08 \n",
      "Save model!\n",
      "Iter:   1300, Train Loss: 0.03338, Train Acc: 100.00%, Val Loss: 0.8173, Val Acc: 77.00%, Time: 0:29:21 *\n",
      "Save model!\n",
      "Iter:   1310, Train Loss: 0.08323, Train Acc: 96.88%, Val Loss: 0.8336, Val Acc: 77.40%, Time: 0:29:35 *\n",
      "Iter:   1320, Train Loss: 0.01893, Train Acc: 100.00%, Val Loss: 0.864, Val Acc: 75.73%, Time: 0:29:49 \n",
      "Iter:   1330, Train Loss: 0.1527, Train Acc: 95.31%, Val Loss: 0.8662, Val Acc: 76.20%, Time: 0:30:02 \n",
      "Iter:   1340, Train Loss: 0.1325, Train Acc: 98.44%, Val Loss: 0.8551, Val Acc: 76.47%, Time: 0:30:15 \n",
      "Iter:   1350, Train Loss: 0.0233, Train Acc: 100.00%, Val Loss: 0.8556, Val Acc: 76.13%, Time: 0:30:28 \n",
      "Iter:   1360, Train Loss: 0.01608, Train Acc: 100.00%, Val Loss: 0.8709, Val Acc: 76.07%, Time: 0:30:42 \n",
      "Iter:   1370, Train Loss: 0.1447, Train Acc: 95.31%, Val Loss: 0.8811, Val Acc: 75.60%, Time: 0:30:55 \n",
      "Iter:   1380, Train Loss: 0.257, Train Acc: 95.31%, Val Loss: 0.9027, Val Acc: 75.13%, Time: 0:31:08 \n",
      "Iter:   1390, Train Loss: 0.01444, Train Acc: 100.00%, Val Loss: 0.8956, Val Acc: 75.40%, Time: 0:31:20 \n",
      "Iter:   1400, Train Loss: 0.1138, Train Acc: 96.88%, Val Loss: 0.8798, Val Acc: 75.93%, Time: 0:31:32 \n",
      "Iter:   1410, Train Loss: 0.1117, Train Acc: 95.31%, Val Loss: 0.9023, Val Acc: 75.67%, Time: 0:31:45 \n",
      "Iter:   1420, Train Loss: 0.1316, Train Acc: 96.88%, Val Loss: 0.8608, Val Acc: 76.60%, Time: 0:31:57 \n",
      "Iter:   1430, Train Loss: 0.121, Train Acc: 95.31%, Val Loss: 0.852, Val Acc: 75.53%, Time: 0:32:09 \n",
      "Iter:   1440, Train Loss: 0.06519, Train Acc: 98.44%, Val Loss: 0.8495, Val Acc: 76.13%, Time: 0:32:22 \n",
      "Iter:   1450, Train Loss: 0.172, Train Acc: 95.31%, Val Loss: 0.8382, Val Acc: 75.80%, Time: 0:32:34 \n",
      "Iter:   1460, Train Loss: 0.05502, Train Acc: 98.44%, Val Loss: 0.8237, Val Acc: 76.00%, Time: 0:32:47 \n",
      "Iter:   1470, Train Loss: 0.04773, Train Acc: 100.00%, Val Loss: 0.8308, Val Acc: 75.53%, Time: 0:32:59 \n",
      "Epoch: 8\n",
      "Iter:   1480, Train Loss: 0.0319, Train Acc: 98.44%, Val Loss: 0.8406, Val Acc: 75.47%, Time: 0:33:12 \n",
      "Iter:   1490, Train Loss: 0.0582, Train Acc: 98.44%, Val Loss: 0.8647, Val Acc: 75.73%, Time: 0:33:24 \n",
      "Iter:   1500, Train Loss: 0.03826, Train Acc: 98.44%, Val Loss: 0.8852, Val Acc: 75.87%, Time: 0:33:36 \n",
      "Iter:   1510, Train Loss: 0.092, Train Acc: 98.44%, Val Loss: 0.9384, Val Acc: 75.53%, Time: 0:33:49 \n",
      "Iter:   1520, Train Loss: 0.02926, Train Acc: 98.44%, Val Loss: 0.9249, Val Acc: 75.80%, Time: 0:34:01 \n",
      "Iter:   1530, Train Loss: 0.05367, Train Acc: 98.44%, Val Loss: 0.9259, Val Acc: 75.93%, Time: 0:34:13 \n",
      "Iter:   1540, Train Loss: 0.009156, Train Acc: 100.00%, Val Loss: 0.913, Val Acc: 76.20%, Time: 0:34:25 \n",
      "Iter:   1550, Train Loss: 0.05355, Train Acc: 98.44%, Val Loss: 0.9363, Val Acc: 76.00%, Time: 0:34:38 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1560, Train Loss: 0.1575, Train Acc: 96.88%, Val Loss: 0.9247, Val Acc: 76.20%, Time: 0:34:50 \n",
      "Iter:   1570, Train Loss: 0.05706, Train Acc: 96.88%, Val Loss: 0.9041, Val Acc: 76.00%, Time: 0:35:03 \n",
      "Iter:   1580, Train Loss: 0.03391, Train Acc: 98.44%, Val Loss: 0.8539, Val Acc: 76.00%, Time: 0:35:15 \n",
      "Iter:   1590, Train Loss: 0.04286, Train Acc: 98.44%, Val Loss: 0.8526, Val Acc: 75.60%, Time: 0:35:28 \n",
      "Iter:   1600, Train Loss: 0.1182, Train Acc: 96.88%, Val Loss: 0.8679, Val Acc: 75.40%, Time: 0:35:40 \n",
      "Iter:   1610, Train Loss: 0.03595, Train Acc: 98.44%, Val Loss: 0.8741, Val Acc: 75.47%, Time: 0:35:52 \n",
      "Iter:   1620, Train Loss: 0.2124, Train Acc: 93.75%, Val Loss: 0.9026, Val Acc: 76.13%, Time: 0:36:05 \n",
      "Iter:   1630, Train Loss: 0.1065, Train Acc: 96.88%, Val Loss: 0.9044, Val Acc: 75.47%, Time: 0:36:17 \n",
      "Iter:   1640, Train Loss: 0.04242, Train Acc: 98.44%, Val Loss: 0.873, Val Acc: 75.60%, Time: 0:36:29 \n",
      "Iter:   1650, Train Loss: 0.1858, Train Acc: 92.19%, Val Loss: 0.8789, Val Acc: 75.67%, Time: 0:36:42 \n",
      "Iter:   1660, Train Loss: 0.02438, Train Acc: 100.00%, Val Loss: 0.8715, Val Acc: 75.67%, Time: 0:36:54 \n",
      "Iter:   1670, Train Loss: 0.06229, Train Acc: 96.88%, Val Loss: 0.8674, Val Acc: 76.13%, Time: 0:37:07 \n",
      "Iter:   1680, Train Loss: 0.02314, Train Acc: 100.00%, Val Loss: 0.8667, Val Acc: 76.27%, Time: 0:37:19 \n",
      "Epoch: 9\n",
      "Iter:   1690, Train Loss: 0.0238, Train Acc: 100.00%, Val Loss: 0.8755, Val Acc: 76.13%, Time: 0:37:31 \n",
      "Iter:   1700, Train Loss: 0.009389, Train Acc: 100.00%, Val Loss: 0.8527, Val Acc: 75.40%, Time: 0:37:44 \n",
      "Iter:   1710, Train Loss: 0.07455, Train Acc: 98.44%, Val Loss: 0.8936, Val Acc: 75.27%, Time: 0:37:56 \n",
      "Iter:   1720, Train Loss: 0.04658, Train Acc: 98.44%, Val Loss: 0.9036, Val Acc: 75.53%, Time: 0:38:08 \n",
      "Iter:   1730, Train Loss: 0.1202, Train Acc: 98.44%, Val Loss:  0.9, Val Acc: 76.13%, Time: 0:38:21 \n",
      "Iter:   1740, Train Loss: 0.07665, Train Acc: 98.44%, Val Loss: 0.9144, Val Acc: 76.27%, Time: 0:38:33 \n",
      "Iter:   1750, Train Loss: 0.08121, Train Acc: 98.44%, Val Loss: 0.9457, Val Acc: 75.73%, Time: 0:38:46 \n",
      "Iter:   1760, Train Loss: 0.1096, Train Acc: 96.88%, Val Loss: 0.9191, Val Acc: 76.27%, Time: 0:38:58 \n",
      "Iter:   1770, Train Loss: 0.1435, Train Acc: 96.88%, Val Loss: 0.9055, Val Acc: 76.20%, Time: 0:39:10 \n",
      "Iter:   1780, Train Loss: 0.006831, Train Acc: 100.00%, Val Loss: 0.8834, Val Acc: 75.53%, Time: 0:39:23 \n",
      "Iter:   1790, Train Loss: 0.06625, Train Acc: 98.44%, Val Loss: 0.8838, Val Acc: 76.40%, Time: 0:39:35 \n",
      "Iter:   1800, Train Loss: 0.08909, Train Acc: 98.44%, Val Loss: 0.9354, Val Acc: 75.20%, Time: 0:39:47 \n",
      "Iter:   1810, Train Loss: 0.03254, Train Acc: 98.44%, Val Loss: 0.9179, Val Acc: 76.27%, Time: 0:40:00 \n",
      "Iter:   1820, Train Loss: 0.1302, Train Acc: 95.31%, Val Loss: 0.9205, Val Acc: 76.33%, Time: 0:40:12 \n",
      "Iter:   1830, Train Loss: 0.1035, Train Acc: 95.31%, Val Loss: 0.8854, Val Acc: 76.27%, Time: 0:40:25 \n",
      "Iter:   1840, Train Loss: 0.05206, Train Acc: 98.44%, Val Loss: 0.8703, Val Acc: 76.53%, Time: 0:40:37 \n",
      "Iter:   1850, Train Loss: 0.02836, Train Acc: 98.44%, Val Loss: 0.8537, Val Acc: 76.53%, Time: 0:40:50 \n",
      "Iter:   1860, Train Loss: 0.06995, Train Acc: 96.88%, Val Loss: 0.8707, Val Acc: 76.67%, Time: 0:41:02 \n",
      "Iter:   1870, Train Loss: 0.1465, Train Acc: 95.31%, Val Loss: 0.8997, Val Acc: 76.33%, Time: 0:41:14 \n",
      "Iter:   1880, Train Loss: 0.05722, Train Acc: 98.44%, Val Loss: 0.8643, Val Acc: 76.27%, Time: 0:41:28 \n",
      "Iter:   1890, Train Loss: 0.07394, Train Acc: 96.88%, Val Loss: 0.8926, Val Acc: 75.93%, Time: 0:41:42 \n",
      "Epoch: 10\n",
      "Iter:   1900, Train Loss: 0.01517, Train Acc: 100.00%, Val Loss: 0.8915, Val Acc: 76.20%, Time: 0:41:58 \n",
      "Iter:   1910, Train Loss: 0.08847, Train Acc: 95.31%, Val Loss: 0.942, Val Acc: 75.47%, Time: 0:42:11 \n",
      "Iter:   1920, Train Loss: 0.05031, Train Acc: 96.88%, Val Loss: 0.9583, Val Acc: 75.93%, Time: 0:42:29 \n",
      "Iter:   1930, Train Loss: 0.05256, Train Acc: 98.44%, Val Loss: 0.9599, Val Acc: 76.07%, Time: 0:42:45 \n",
      "Iter:   1940, Train Loss: 0.0489, Train Acc: 96.88%, Val Loss: 0.9588, Val Acc: 75.80%, Time: 0:43:03 \n",
      "Iter:   1950, Train Loss: 0.04571, Train Acc: 98.44%, Val Loss: 0.9555, Val Acc: 75.87%, Time: 0:43:20 \n",
      "Iter:   1960, Train Loss: 0.03706, Train Acc: 100.00%, Val Loss: 0.93, Val Acc: 75.73%, Time: 0:43:34 \n",
      "Iter:   1970, Train Loss: 0.02861, Train Acc: 98.44%, Val Loss: 0.9596, Val Acc: 76.40%, Time: 0:43:53 \n",
      "Iter:   1980, Train Loss: 0.04174, Train Acc: 100.00%, Val Loss: 0.9511, Val Acc: 75.73%, Time: 0:44:09 \n",
      "Iter:   1990, Train Loss: 0.2421, Train Acc: 96.88%, Val Loss: 0.9551, Val Acc: 74.73%, Time: 0:44:26 \n",
      "Iter:   2000, Train Loss: 0.07217, Train Acc: 95.31%, Val Loss: 0.9552, Val Acc: 75.67%, Time: 0:44:41 \n",
      "Iter:   2010, Train Loss: 0.02753, Train Acc: 98.44%, Val Loss: 0.9759, Val Acc: 75.60%, Time: 0:44:59 \n",
      "Iter:   2020, Train Loss: 0.00466, Train Acc: 100.00%, Val Loss: 0.9887, Val Acc: 76.53%, Time: 0:45:16 \n",
      "Iter:   2030, Train Loss: 0.05927, Train Acc: 98.44%, Val Loss: 0.9601, Val Acc: 75.40%, Time: 0:45:32 \n",
      "Iter:   2040, Train Loss: 0.02149, Train Acc: 98.44%, Val Loss: 0.9058, Val Acc: 76.00%, Time: 0:45:50 \n",
      "Iter:   2050, Train Loss: 0.01909, Train Acc: 100.00%, Val Loss: 0.8904, Val Acc: 75.93%, Time: 0:46:07 \n",
      "Iter:   2060, Train Loss: 0.07719, Train Acc: 98.44%, Val Loss: 0.9281, Val Acc: 76.47%, Time: 0:46:23 \n",
      "Iter:   2070, Train Loss: 0.1152, Train Acc: 96.88%, Val Loss: 0.9528, Val Acc: 75.93%, Time: 0:46:37 \n",
      "Iter:   2080, Train Loss: 0.08379, Train Acc: 96.88%, Val Loss: 0.9529, Val Acc: 76.33%, Time: 0:46:53 \n",
      "Iter:   2090, Train Loss: 0.0541, Train Acc: 98.44%, Val Loss: 0.9426, Val Acc: 76.00%, Time: 0:47:07 \n",
      "Iter:   2100, Train Loss: 0.0944, Train Acc: 96.88%, Val Loss: 0.9625, Val Acc: 75.40%, Time: 0:47:22 \n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(param_saving_path, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "    \n",
    "# data_save = {\"wordToID\": data['wordToID'], \"seq_length\": data['seq_length']}\n",
    "\n",
    "# new_saving_path = \"../data/param-classify-test.dat\"\n",
    "# with open(new_saving_path, 'wb') as f:\n",
    "#     pickle.dump(data_save, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
