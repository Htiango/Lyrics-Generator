{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNNConfig(object):\n",
    "    \"\"\"CNN param\"\"\"\n",
    "\n",
    "    embedding_dim = 64  # word vector dimension\n",
    "    seq_length = 800  # sequense length\n",
    "    num_classes = 3  # class number\n",
    "    num_filters = 256  # kernel number\n",
    "    kernel_size = 5  # kernel size\n",
    "    vocab_size = 5000  # vocab size\n",
    "\n",
    "    hidden_dim = 128  # fully connected neuro number\n",
    "\n",
    "    dropout_keep_prob = 0.5  # dropout keeping rate\n",
    "    learning_rate = 1e-3  # learning rate\n",
    "\n",
    "    batch_size = 64  # batch size\n",
    "    num_epochs = 10  # total epoch number\n",
    "\n",
    "    print_per_batch = 10  # output iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"text classification，CNN model\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, self.config.seq_length], name='input_x')\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, self.config.num_classes], name='input_y')\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "        self.cnn()\n",
    "\n",
    "    def cnn(self):\n",
    "        \"\"\"CNN model\"\"\"\n",
    "        # word embedding\n",
    "        with tf.device('/cpu:0'):\n",
    "            embedding = tf.get_variable('embedding', [self.config.vocab_size, self.config.embedding_dim])\n",
    "            embedding_inputs = tf.nn.embedding_lookup(embedding, self.input_x)\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            # CNN layer\n",
    "            conv = tf.layers.conv1d(embedding_inputs, self.config.num_filters, self.config.kernel_size, name='conv')\n",
    "            # global max pooling layer\n",
    "            gmp = tf.reduce_max(conv, reduction_indices=[1], name='gmp')\n",
    "\n",
    "        with tf.name_scope(\"score\"):\n",
    "            # fully connected layer，with dropout and ReLU\n",
    "            fc = tf.layers.dense(gmp, self.config.hidden_dim, name='fc1')\n",
    "            fc = tf.contrib.layers.dropout(fc, self.keep_prob)\n",
    "            fc = tf.nn.relu(fc)\n",
    "\n",
    "            # classifier\n",
    "            self.logits = tf.layers.dense(fc, self.config.num_classes, name='fc2')\n",
    "            self.y_pred_cls = tf.argmax(tf.nn.softmax(self.logits), 1)  # predictor\n",
    "\n",
    "        with tf.name_scope(\"optimize\"):\n",
    "            # loss function，cross entropy\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(cross_entropy)\n",
    "            # optimizor\n",
    "            self.optim = tf.train.AdamOptimizer(learning_rate=self.config.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            # accuracy\n",
    "            correct_pred = tf.equal(tf.argmax(self.input_y, 1), self.y_pred_cls)\n",
    "            self.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/textcnn'\n",
    "save_path = os.path.join(save_dir, 'best_validation')\n",
    "param_saving_path = '../data/param-classify.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x, y, batch_size=64):\n",
    "    \"\"\"generate batchsize data\"\"\"\n",
    "    data_len = len(x)\n",
    "    num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuffle = x[indices]\n",
    "    y_shuffle = y[indices]\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size, data_len)\n",
    "        yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dif(start_time):\n",
    "    \"\"\"get time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "def feed_data(x_batch, y_batch, keep_prob):\n",
    "    feed_dict = {\n",
    "        model.input_x: x_batch,\n",
    "        model.input_y: y_batch,\n",
    "        model.keep_prob: keep_prob\n",
    "    }\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def evaluate(sess, x_, y_):\n",
    "    \"\"\"evaluate the loss and accuracy\"\"\"\n",
    "    data_len = len(x_)\n",
    "    batch_eval = batch_iter(x_, y_, 128)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    for x_batch, y_batch in batch_eval:\n",
    "        batch_len = len(x_batch)\n",
    "        feed_dict = feed_data(x_batch, y_batch, 1.0)\n",
    "        loss, acc = sess.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "        total_loss += loss * batch_len\n",
    "        total_acc += acc * batch_len\n",
    "\n",
    "    return total_loss / data_len, total_acc / data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    saver = tf.train.Saver()\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    validation_rate = 0.1\n",
    "    idx = int(x.shape[0] * validation_rate)\n",
    "    x_train = x[idx:]\n",
    "    x_val = x[:idx]\n",
    "    y_train = y[idx:]\n",
    "    y_val = y[:idx]\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_val.shape)\n",
    "    \n",
    "    \n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Training and evaluating...')\n",
    "    start_time = time.time()\n",
    "    total_batch = 0  # total batch number\n",
    "    best_acc_val = 0.0  # best validation accuracy\n",
    "    last_improved = 0  # last improving\n",
    "    require_improvement = 1000  # if not improving after 1000 iterations, end early\n",
    "    \n",
    "    flag = False\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch:', epoch + 1)\n",
    "        batch_train = batch_iter(x_train, y_train, config.batch_size)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            feed_dict = feed_data(x_batch, y_batch, config.dropout_keep_prob)\n",
    "\n",
    "            if total_batch % config.print_per_batch == 0:\n",
    "                # get the loss and accuracy on training set and validation set\n",
    "                feed_dict[model.keep_prob] = 1.0\n",
    "                loss_train, acc_train = session.run([model.loss, model.acc], feed_dict=feed_dict)\n",
    "                loss_val, acc_val = evaluate(session, x_val, y_val)  # todo\n",
    "\n",
    "                if acc_val > best_acc_val:\n",
    "                    # save the best result\n",
    "                    best_acc_val = acc_val\n",
    "                    last_improved = total_batch\n",
    "                    saver.save(sess=session, save_path=save_path)\n",
    "                    print(\"Save model!\")\n",
    "                    improved_str = '*'\n",
    "                else:\n",
    "                    improved_str = ''\n",
    "\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = 'Iter: {0:>6}, Train Loss: {1:>4.4}, Train Acc: {2:>5.4%},' \\\n",
    "                      + ' Val Loss: {3:>4.4}, Val Acc: {4:>5.4%}, Time: {5} {6}'\n",
    "                print(msg.format(total_batch, loss_train, acc_train, loss_val, acc_val, time_dif, improved_str))\n",
    "\n",
    "            session.run(model.optim, feed_dict=feed_dict)  # 运行优化\n",
    "            total_batch += 1\n",
    "\n",
    "            if total_batch - last_improved > require_improvement:\n",
    "                # early end\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break \n",
    "        if flag:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "config = TCNNConfig()\n",
    "with open(param_saving_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "print(len(x))\n",
    "P = np.random.permutation(len(x))\n",
    "x = x[P]\n",
    "y = y[P]\n",
    "\n",
    "wordToID = data['wordToID']\n",
    "seq_length = data['seq_length']\n",
    "config.vocab_size = len(wordToID)\n",
    "config.seq_length = seq_length\n",
    "\n",
    "model = TextCNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 800)\n",
      "(1500, 800)\n",
      "(13500, 3)\n",
      "(1500, 3)\n",
      "Training and evaluating...\n",
      "Epoch: 1\n",
      "Save model!\n",
      "Iter:      0, Train Loss: 1.097, Train Acc: 42.1875%, Val Loss: 1.099, Val Acc: 32.6000%, Time: 0:00:04 *\n",
      "Save model!\n",
      "Iter:     10, Train Loss: 1.094, Train Acc: 37.5000%, Val Loss: 1.098, Val Acc: 34.0000%, Time: 0:00:18 *\n",
      "Save model!\n",
      "Iter:     20, Train Loss: 1.077, Train Acc: 45.3125%, Val Loss: 1.086, Val Acc: 38.3333%, Time: 0:00:34 *\n",
      "Save model!\n",
      "Iter:     30, Train Loss: 1.061, Train Acc: 56.2500%, Val Loss: 1.058, Val Acc: 61.6000%, Time: 0:00:50 *\n",
      "Iter:     40, Train Loss: 1.013, Train Acc: 46.8750%, Val Loss: 0.975, Val Acc: 59.8000%, Time: 0:01:04 \n",
      "Iter:     50, Train Loss: 0.7824, Train Acc: 67.1875%, Val Loss: 0.8201, Val Acc: 59.1333%, Time: 0:01:17 \n",
      "Iter:     60, Train Loss: 0.7701, Train Acc: 59.3750%, Val Loss: 0.7119, Val Acc: 59.8667%, Time: 0:01:33 \n",
      "Save model!\n",
      "Iter:     70, Train Loss: 0.6987, Train Acc: 64.0625%, Val Loss: 0.6899, Val Acc: 62.4000%, Time: 0:01:47 *\n",
      "Save model!\n",
      "Iter:     80, Train Loss: 0.6103, Train Acc: 64.0625%, Val Loss: 0.6769, Val Acc: 63.9333%, Time: 0:02:00 *\n",
      "Save model!\n",
      "Iter:     90, Train Loss: 0.7388, Train Acc: 68.7500%, Val Loss: 0.6573, Val Acc: 67.2000%, Time: 0:02:14 *\n",
      "Iter:    100, Train Loss: 0.868, Train Acc: 56.2500%, Val Loss: 0.6479, Val Acc: 65.2667%, Time: 0:02:28 \n",
      "Save model!\n",
      "Iter:    110, Train Loss: 0.6928, Train Acc: 68.7500%, Val Loss: 0.6336, Val Acc: 67.5333%, Time: 0:02:41 *\n",
      "Save model!\n",
      "Iter:    120, Train Loss: 0.6537, Train Acc: 62.5000%, Val Loss: 0.6235, Val Acc: 68.8667%, Time: 0:02:55 *\n",
      "Iter:    130, Train Loss: 0.5842, Train Acc: 65.6250%, Val Loss: 0.63, Val Acc: 67.7333%, Time: 0:03:09 \n",
      "Save model!\n",
      "Iter:    140, Train Loss: 0.6563, Train Acc: 68.7500%, Val Loss: 0.6158, Val Acc: 69.2000%, Time: 0:03:24 *\n",
      "Save model!\n",
      "Iter:    150, Train Loss: 0.6587, Train Acc: 68.7500%, Val Loss: 0.6103, Val Acc: 70.2667%, Time: 0:03:37 *\n",
      "Iter:    160, Train Loss: 0.5384, Train Acc: 76.5625%, Val Loss: 0.6018, Val Acc: 70.2667%, Time: 0:03:50 \n",
      "Save model!\n",
      "Iter:    170, Train Loss: 0.6559, Train Acc: 64.0625%, Val Loss: 0.5953, Val Acc: 70.6000%, Time: 0:04:05 *\n",
      "Iter:    180, Train Loss: 0.5743, Train Acc: 70.3125%, Val Loss: 0.5901, Val Acc: 70.5333%, Time: 0:04:18 \n",
      "Iter:    190, Train Loss: 0.4972, Train Acc: 73.4375%, Val Loss: 0.5933, Val Acc: 69.7333%, Time: 0:04:31 \n",
      "Save model!\n",
      "Iter:    200, Train Loss: 0.5262, Train Acc: 75.0000%, Val Loss: 0.5783, Val Acc: 70.6667%, Time: 0:04:44 *\n",
      "Save model!\n",
      "Iter:    210, Train Loss: 0.5114, Train Acc: 76.6667%, Val Loss: 0.5748, Val Acc: 72.0667%, Time: 0:04:58 *\n",
      "Epoch: 2\n",
      "Iter:    220, Train Loss: 0.4141, Train Acc: 81.2500%, Val Loss: 0.5721, Val Acc: 71.6667%, Time: 0:05:12 \n",
      "Iter:    230, Train Loss: 0.5029, Train Acc: 68.7500%, Val Loss: 0.5733, Val Acc: 71.8667%, Time: 0:05:26 \n",
      "Save model!\n",
      "Iter:    240, Train Loss: 0.5427, Train Acc: 70.3125%, Val Loss: 0.5682, Val Acc: 72.2667%, Time: 0:05:39 *\n",
      "Save model!\n",
      "Iter:    250, Train Loss: 0.5351, Train Acc: 79.6875%, Val Loss: 0.5658, Val Acc: 72.3333%, Time: 0:05:53 *\n",
      "Iter:    260, Train Loss: 0.4703, Train Acc: 75.0000%, Val Loss: 0.5638, Val Acc: 71.9333%, Time: 0:06:06 \n",
      "Save model!\n",
      "Iter:    270, Train Loss: 0.7805, Train Acc: 78.1250%, Val Loss: 0.5592, Val Acc: 73.0667%, Time: 0:06:19 *\n",
      "Save model!\n",
      "Iter:    280, Train Loss: 0.4084, Train Acc: 82.8125%, Val Loss: 0.558, Val Acc: 73.4667%, Time: 0:06:33 *\n",
      "Iter:    290, Train Loss: 0.5803, Train Acc: 75.0000%, Val Loss: 0.553, Val Acc: 73.0667%, Time: 0:06:46 \n",
      "Iter:    300, Train Loss: 0.3933, Train Acc: 78.1250%, Val Loss: 0.5595, Val Acc: 72.4667%, Time: 0:06:59 \n",
      "Iter:    310, Train Loss: 0.4404, Train Acc: 76.5625%, Val Loss: 0.5588, Val Acc: 72.6000%, Time: 0:07:12 \n",
      "Iter:    320, Train Loss: 0.6245, Train Acc: 68.7500%, Val Loss: 0.5606, Val Acc: 71.9333%, Time: 0:07:25 \n",
      "Iter:    330, Train Loss: 0.4984, Train Acc: 78.1250%, Val Loss: 0.5746, Val Acc: 72.3333%, Time: 0:07:37 \n",
      "Iter:    340, Train Loss: 0.4508, Train Acc: 81.2500%, Val Loss: 0.5541, Val Acc: 73.4000%, Time: 0:07:50 \n",
      "Save model!\n",
      "Iter:    350, Train Loss: 0.5808, Train Acc: 71.8750%, Val Loss: 0.5449, Val Acc: 74.2000%, Time: 0:08:02 *\n",
      "Save model!\n",
      "Iter:    360, Train Loss: 0.5513, Train Acc: 76.5625%, Val Loss: 0.5395, Val Acc: 75.1333%, Time: 0:08:16 *\n",
      "Iter:    370, Train Loss: 0.4563, Train Acc: 79.6875%, Val Loss: 0.5509, Val Acc: 73.6667%, Time: 0:08:30 \n",
      "Save model!\n",
      "Iter:    380, Train Loss: 0.4165, Train Acc: 82.8125%, Val Loss: 0.5462, Val Acc: 75.6667%, Time: 0:08:43 *\n",
      "Iter:    390, Train Loss: 0.5181, Train Acc: 71.8750%, Val Loss: 0.5285, Val Acc: 74.7333%, Time: 0:08:56 \n",
      "Iter:    400, Train Loss: 0.5597, Train Acc: 71.8750%, Val Loss: 0.5361, Val Acc: 74.2000%, Time: 0:09:09 \n",
      "Iter:    410, Train Loss: 0.5072, Train Acc: 76.5625%, Val Loss: 0.5348, Val Acc: 74.5333%, Time: 0:09:22 \n",
      "Iter:    420, Train Loss: 0.545, Train Acc: 78.1250%, Val Loss: 0.5339, Val Acc: 74.4000%, Time: 0:09:35 \n",
      "Epoch: 3\n",
      "Save model!\n",
      "Iter:    430, Train Loss: 0.3075, Train Acc: 89.0625%, Val Loss: 0.5319, Val Acc: 76.0000%, Time: 0:09:47 *\n",
      "Save model!\n",
      "Iter:    440, Train Loss: 0.2747, Train Acc: 89.0625%, Val Loss: 0.5342, Val Acc: 76.1333%, Time: 0:10:01 *\n",
      "Save model!\n",
      "Iter:    450, Train Loss: 0.233, Train Acc: 92.1875%, Val Loss: 0.5388, Val Acc: 76.1333%, Time: 0:10:15 *\n",
      "Iter:    460, Train Loss: 0.3451, Train Acc: 82.8125%, Val Loss: 0.547, Val Acc: 75.7333%, Time: 0:10:28 \n",
      "Iter:    470, Train Loss: 0.2416, Train Acc: 90.6250%, Val Loss: 0.5641, Val Acc: 75.2000%, Time: 0:10:41 \n",
      "Iter:    480, Train Loss: 0.3821, Train Acc: 90.6250%, Val Loss: 0.5693, Val Acc: 75.2667%, Time: 0:10:54 \n",
      "Iter:    490, Train Loss: 0.3528, Train Acc: 81.2500%, Val Loss: 0.5766, Val Acc: 74.5333%, Time: 0:11:06 \n",
      "Iter:    500, Train Loss: 0.3342, Train Acc: 85.9375%, Val Loss: 0.5483, Val Acc: 75.0667%, Time: 0:11:19 \n",
      "Iter:    510, Train Loss: 0.3689, Train Acc: 87.5000%, Val Loss: 0.5464, Val Acc: 75.2000%, Time: 0:11:31 \n",
      "Save model!\n",
      "Iter:    520, Train Loss: 0.3008, Train Acc: 85.9375%, Val Loss: 0.5427, Val Acc: 76.2000%, Time: 0:11:44 *\n",
      "Save model!\n",
      "Iter:    530, Train Loss: 0.4387, Train Acc: 79.6875%, Val Loss: 0.5545, Val Acc: 76.3333%, Time: 0:11:57 *\n",
      "Save model!\n",
      "Iter:    540, Train Loss: 0.2266, Train Acc: 90.6250%, Val Loss: 0.5435, Val Acc: 77.2000%, Time: 0:12:11 *\n",
      "Iter:    550, Train Loss: 0.385, Train Acc: 84.3750%, Val Loss: 0.5379, Val Acc: 76.4000%, Time: 0:12:24 \n",
      "Save model!\n",
      "Iter:    560, Train Loss: 0.4423, Train Acc: 78.1250%, Val Loss: 0.5341, Val Acc: 77.2667%, Time: 0:12:37 *\n",
      "Iter:    570, Train Loss: 0.2475, Train Acc: 90.6250%, Val Loss: 0.5447, Val Acc: 75.2000%, Time: 0:12:50 \n",
      "Iter:    580, Train Loss: 0.3543, Train Acc: 82.8125%, Val Loss: 0.5569, Val Acc: 75.9333%, Time: 0:13:03 \n",
      "Iter:    590, Train Loss: 0.3658, Train Acc: 85.9375%, Val Loss: 0.5489, Val Acc: 76.0000%, Time: 0:13:17 \n",
      "Iter:    600, Train Loss: 0.4124, Train Acc: 84.3750%, Val Loss: 0.5634, Val Acc: 75.2000%, Time: 0:13:29 \n",
      "Iter:    610, Train Loss: 0.3676, Train Acc: 89.0625%, Val Loss: 0.556, Val Acc: 75.8667%, Time: 0:13:42 \n",
      "Iter:    620, Train Loss: 0.2808, Train Acc: 90.6250%, Val Loss: 0.5483, Val Acc: 76.4000%, Time: 0:13:55 \n",
      "Iter:    630, Train Loss: 0.3733, Train Acc: 84.3750%, Val Loss: 0.5443, Val Acc: 76.3333%, Time: 0:14:07 \n",
      "Epoch: 4\n",
      "Iter:    640, Train Loss: 0.1844, Train Acc: 92.1875%, Val Loss: 0.5557, Val Acc: 74.9333%, Time: 0:14:19 \n",
      "Iter:    650, Train Loss: 0.1746, Train Acc: 95.3125%, Val Loss: 0.5774, Val Acc: 76.2000%, Time: 0:14:32 \n",
      "Iter:    660, Train Loss: 0.1685, Train Acc: 98.4375%, Val Loss: 0.5934, Val Acc: 76.3333%, Time: 0:14:44 \n",
      "Iter:    670, Train Loss: 0.1985, Train Acc: 90.6250%, Val Loss: 0.6175, Val Acc: 76.6667%, Time: 0:14:56 \n",
      "Iter:    680, Train Loss: 0.2337, Train Acc: 89.0625%, Val Loss: 0.6043, Val Acc: 76.4667%, Time: 0:15:09 \n",
      "Iter:    690, Train Loss: 0.285, Train Acc: 89.0625%, Val Loss: 0.6134, Val Acc: 76.0000%, Time: 0:15:21 \n",
      "Iter:    700, Train Loss: 0.1924, Train Acc: 89.0625%, Val Loss: 0.6066, Val Acc: 76.6667%, Time: 0:15:34 \n",
      "Iter:    710, Train Loss: 0.2801, Train Acc: 87.5000%, Val Loss: 0.6293, Val Acc: 75.6000%, Time: 0:15:46 \n",
      "Iter:    720, Train Loss: 0.3109, Train Acc: 93.7500%, Val Loss: 0.6382, Val Acc: 76.2000%, Time: 0:15:59 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model!\n",
      "Iter:    730, Train Loss: 0.2358, Train Acc: 95.3125%, Val Loss: 0.6333, Val Acc: 77.4667%, Time: 0:16:11 *\n",
      "Iter:    740, Train Loss: 0.3518, Train Acc: 87.5000%, Val Loss: 0.6369, Val Acc: 76.4667%, Time: 0:16:25 \n",
      "Iter:    750, Train Loss: 0.3315, Train Acc: 84.3750%, Val Loss: 0.6356, Val Acc: 77.0000%, Time: 0:16:38 \n",
      "Iter:    760, Train Loss: 0.2312, Train Acc: 90.6250%, Val Loss: 0.6393, Val Acc: 77.1333%, Time: 0:16:51 \n",
      "Iter:    770, Train Loss: 0.2917, Train Acc: 90.6250%, Val Loss: 0.6508, Val Acc: 75.2000%, Time: 0:17:03 \n",
      "Iter:    780, Train Loss: 0.1641, Train Acc: 95.3125%, Val Loss: 0.6236, Val Acc: 76.6000%, Time: 0:17:16 \n",
      "Iter:    790, Train Loss: 0.2028, Train Acc: 89.0625%, Val Loss: 0.6346, Val Acc: 75.6000%, Time: 0:17:29 \n",
      "Iter:    800, Train Loss: 0.162, Train Acc: 96.8750%, Val Loss: 0.6188, Val Acc: 76.8667%, Time: 0:17:41 \n",
      "Iter:    810, Train Loss: 0.241, Train Acc: 93.7500%, Val Loss: 0.6383, Val Acc: 75.9333%, Time: 0:17:53 \n",
      "Iter:    820, Train Loss: 0.1591, Train Acc: 93.7500%, Val Loss: 0.6349, Val Acc: 76.8667%, Time: 0:18:06 \n",
      "Iter:    830, Train Loss: 0.2054, Train Acc: 87.5000%, Val Loss: 0.6168, Val Acc: 76.0000%, Time: 0:18:18 \n",
      "Iter:    840, Train Loss: 0.2345, Train Acc: 90.6250%, Val Loss: 0.6259, Val Acc: 76.0667%, Time: 0:18:31 \n",
      "Epoch: 5\n",
      "Iter:    850, Train Loss: 0.05664, Train Acc: 98.4375%, Val Loss: 0.6615, Val Acc: 76.3333%, Time: 0:18:43 \n",
      "Iter:    860, Train Loss: 0.1112, Train Acc: 98.4375%, Val Loss: 0.6773, Val Acc: 76.1333%, Time: 0:18:57 \n",
      "Iter:    870, Train Loss: 0.09628, Train Acc: 98.4375%, Val Loss: 0.6868, Val Acc: 76.2000%, Time: 0:19:09 \n",
      "Iter:    880, Train Loss: 0.06243, Train Acc: 100.0000%, Val Loss: 0.6992, Val Acc: 76.2667%, Time: 0:19:22 \n",
      "Iter:    890, Train Loss: 0.09475, Train Acc: 95.3125%, Val Loss: 0.7314, Val Acc: 76.0667%, Time: 0:19:35 \n",
      "Iter:    900, Train Loss: 0.1713, Train Acc: 95.3125%, Val Loss: 0.7513, Val Acc: 75.3333%, Time: 0:19:47 \n",
      "Iter:    910, Train Loss: 0.08922, Train Acc: 96.8750%, Val Loss: 0.7518, Val Acc: 75.9333%, Time: 0:19:59 \n",
      "Iter:    920, Train Loss: 0.093, Train Acc: 96.8750%, Val Loss: 0.7382, Val Acc: 75.7333%, Time: 0:20:12 \n",
      "Iter:    930, Train Loss: 0.1186, Train Acc: 95.3125%, Val Loss: 0.7332, Val Acc: 75.2667%, Time: 0:20:24 \n",
      "Iter:    940, Train Loss: 0.09, Train Acc: 96.8750%, Val Loss: 0.7268, Val Acc: 76.5333%, Time: 0:20:38 \n",
      "Iter:    950, Train Loss: 0.195, Train Acc: 95.3125%, Val Loss: 0.7033, Val Acc: 75.8667%, Time: 0:20:52 \n",
      "Iter:    960, Train Loss: 0.1206, Train Acc: 95.3125%, Val Loss: 0.6887, Val Acc: 75.8667%, Time: 0:21:06 \n",
      "Iter:    970, Train Loss: 0.1348, Train Acc: 95.3125%, Val Loss: 0.6984, Val Acc: 76.7333%, Time: 0:21:19 \n",
      "Iter:    980, Train Loss: 0.213, Train Acc: 93.7500%, Val Loss: 0.7068, Val Acc: 75.9333%, Time: 0:21:32 \n",
      "Iter:    990, Train Loss: 0.1805, Train Acc: 95.3125%, Val Loss: 0.7209, Val Acc: 74.8000%, Time: 0:21:45 \n",
      "Iter:   1000, Train Loss: 0.09486, Train Acc: 95.3125%, Val Loss: 0.7328, Val Acc: 76.1333%, Time: 0:21:58 \n",
      "Iter:   1010, Train Loss: 0.0951, Train Acc: 98.4375%, Val Loss: 0.7511, Val Acc: 76.4667%, Time: 0:22:12 \n",
      "Iter:   1020, Train Loss: 0.05921, Train Acc: 96.8750%, Val Loss: 0.7459, Val Acc: 76.4667%, Time: 0:22:25 \n",
      "Iter:   1030, Train Loss: 0.1139, Train Acc: 96.8750%, Val Loss: 0.7403, Val Acc: 76.4667%, Time: 0:22:39 \n",
      "Iter:   1040, Train Loss: 0.1676, Train Acc: 95.3125%, Val Loss: 0.7326, Val Acc: 76.3333%, Time: 0:22:52 \n",
      "Iter:   1050, Train Loss: 0.07709, Train Acc: 98.4375%, Val Loss: 0.7184, Val Acc: 76.4667%, Time: 0:23:05 \n",
      "Epoch: 6\n",
      "Iter:   1060, Train Loss: 0.03826, Train Acc: 98.4375%, Val Loss: 0.7195, Val Acc: 76.8667%, Time: 0:23:18 \n",
      "Iter:   1070, Train Loss: 0.04593, Train Acc: 98.4375%, Val Loss: 0.7572, Val Acc: 76.3333%, Time: 0:23:31 \n",
      "Iter:   1080, Train Loss: 0.04029, Train Acc: 98.4375%, Val Loss: 0.769, Val Acc: 76.4000%, Time: 0:23:43 \n",
      "Iter:   1090, Train Loss: 0.05109, Train Acc: 98.4375%, Val Loss: 0.7918, Val Acc: 76.1333%, Time: 0:23:56 \n",
      "Iter:   1100, Train Loss: 0.06097, Train Acc: 96.8750%, Val Loss: 0.8012, Val Acc: 76.3333%, Time: 0:24:08 \n",
      "Iter:   1110, Train Loss: 0.06985, Train Acc: 98.4375%, Val Loss: 0.7951, Val Acc: 76.2667%, Time: 0:24:21 \n",
      "Iter:   1120, Train Loss: 0.1301, Train Acc: 96.8750%, Val Loss: 0.82, Val Acc: 75.6000%, Time: 0:24:34 \n",
      "Iter:   1130, Train Loss: 0.02156, Train Acc: 100.0000%, Val Loss: 0.8192, Val Acc: 76.0667%, Time: 0:24:46 \n",
      "Iter:   1140, Train Loss: 0.06753, Train Acc: 98.4375%, Val Loss: 0.8057, Val Acc: 76.3333%, Time: 0:24:58 \n",
      "Iter:   1150, Train Loss: 0.07588, Train Acc: 98.4375%, Val Loss: 0.7969, Val Acc: 76.8667%, Time: 0:25:11 \n",
      "Iter:   1160, Train Loss: 0.1116, Train Acc: 96.8750%, Val Loss: 0.8188, Val Acc: 76.4000%, Time: 0:25:24 \n",
      "Iter:   1170, Train Loss: 0.08003, Train Acc: 98.4375%, Val Loss: 0.8122, Val Acc: 76.0667%, Time: 0:25:36 \n",
      "Iter:   1180, Train Loss: 0.01779, Train Acc: 100.0000%, Val Loss: 0.7981, Val Acc: 76.7333%, Time: 0:25:49 \n",
      "Iter:   1190, Train Loss: 0.1797, Train Acc: 92.1875%, Val Loss: 0.8209, Val Acc: 76.6667%, Time: 0:26:01 \n",
      "Iter:   1200, Train Loss: 0.09272, Train Acc: 98.4375%, Val Loss: 0.7741, Val Acc: 76.2667%, Time: 0:26:13 \n",
      "Iter:   1210, Train Loss: 0.1562, Train Acc: 96.8750%, Val Loss: 0.7996, Val Acc: 75.6000%, Time: 0:26:26 \n",
      "Iter:   1220, Train Loss: 0.1058, Train Acc: 96.8750%, Val Loss: 0.7764, Val Acc: 76.3333%, Time: 0:26:38 \n",
      "Iter:   1230, Train Loss: 0.077, Train Acc: 96.8750%, Val Loss: 0.7939, Val Acc: 75.9333%, Time: 0:26:50 \n",
      "Iter:   1240, Train Loss: 0.0617, Train Acc: 98.4375%, Val Loss: 0.7845, Val Acc: 76.4667%, Time: 0:27:03 \n",
      "Iter:   1250, Train Loss: 0.3976, Train Acc: 90.6250%, Val Loss: 0.8377, Val Acc: 75.4000%, Time: 0:27:15 \n",
      "Iter:   1260, Train Loss: 0.02464, Train Acc: 100.0000%, Val Loss: 0.7708, Val Acc: 76.0000%, Time: 0:27:28 \n",
      "Epoch: 7\n",
      "Iter:   1270, Train Loss: 0.09262, Train Acc: 96.8750%, Val Loss: 0.7657, Val Acc: 75.1333%, Time: 0:27:43 \n",
      "Iter:   1280, Train Loss: 0.07774, Train Acc: 98.4375%, Val Loss: 0.7593, Val Acc: 75.8667%, Time: 0:27:58 \n",
      "Iter:   1290, Train Loss: 0.0138, Train Acc: 100.0000%, Val Loss: 0.8002, Val Acc: 76.1333%, Time: 0:28:13 \n",
      "Iter:   1300, Train Loss: 0.112, Train Acc: 96.8750%, Val Loss: 0.8226, Val Acc: 75.6000%, Time: 0:28:28 \n",
      "Iter:   1310, Train Loss: 0.04413, Train Acc: 96.8750%, Val Loss: 0.8432, Val Acc: 75.2667%, Time: 0:28:43 \n",
      "Iter:   1320, Train Loss: 0.031, Train Acc: 98.4375%, Val Loss: 0.8753, Val Acc: 75.5333%, Time: 0:28:59 \n",
      "Iter:   1330, Train Loss: 0.04404, Train Acc: 98.4375%, Val Loss: 0.8802, Val Acc: 75.0000%, Time: 0:29:14 \n",
      "Iter:   1340, Train Loss: 0.1755, Train Acc: 96.8750%, Val Loss: 0.8352, Val Acc: 75.0000%, Time: 0:29:29 \n",
      "Iter:   1350, Train Loss: 0.07329, Train Acc: 98.4375%, Val Loss: 0.8353, Val Acc: 75.0667%, Time: 0:29:44 \n",
      "Iter:   1360, Train Loss: 0.05493, Train Acc: 98.4375%, Val Loss: 0.8309, Val Acc: 76.0000%, Time: 0:29:58 \n",
      "Iter:   1370, Train Loss: 0.09387, Train Acc: 96.8750%, Val Loss: 0.8464, Val Acc: 76.8667%, Time: 0:30:10 \n",
      "Iter:   1380, Train Loss: 0.03491, Train Acc: 98.4375%, Val Loss: 0.8356, Val Acc: 75.6000%, Time: 0:30:23 \n",
      "Iter:   1390, Train Loss: 0.09097, Train Acc: 96.8750%, Val Loss: 0.8307, Val Acc: 76.1333%, Time: 0:30:35 \n",
      "Iter:   1400, Train Loss: 0.1062, Train Acc: 96.8750%, Val Loss: 0.8451, Val Acc: 76.4000%, Time: 0:30:48 \n",
      "Iter:   1410, Train Loss: 0.1685, Train Acc: 96.8750%, Val Loss: 0.8211, Val Acc: 76.4667%, Time: 0:31:00 \n",
      "Iter:   1420, Train Loss: 0.03243, Train Acc: 100.0000%, Val Loss: 0.8307, Val Acc: 75.6667%, Time: 0:31:12 \n",
      "Iter:   1430, Train Loss: 0.1188, Train Acc: 96.8750%, Val Loss: 0.8769, Val Acc: 75.4667%, Time: 0:31:26 \n",
      "Iter:   1440, Train Loss: 0.1138, Train Acc: 96.8750%, Val Loss: 0.8621, Val Acc: 75.5333%, Time: 0:31:38 \n",
      "Iter:   1450, Train Loss: 0.01622, Train Acc: 100.0000%, Val Loss: 0.8464, Val Acc: 75.6667%, Time: 0:31:50 \n",
      "Iter:   1460, Train Loss: 0.06283, Train Acc: 98.4375%, Val Loss: 0.8316, Val Acc: 75.7333%, Time: 0:32:03 \n",
      "Iter:   1470, Train Loss: 0.05564, Train Acc: 98.4375%, Val Loss: 0.8752, Val Acc: 74.8667%, Time: 0:32:15 \n",
      "Epoch: 8\n",
      "Iter:   1480, Train Loss: 0.09565, Train Acc: 96.8750%, Val Loss: 0.8772, Val Acc: 74.7333%, Time: 0:32:27 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1490, Train Loss: 0.0624, Train Acc: 98.4375%, Val Loss: 0.8605, Val Acc: 75.1333%, Time: 0:32:40 \n",
      "Iter:   1500, Train Loss: 0.07063, Train Acc: 96.8750%, Val Loss: 0.9003, Val Acc: 76.0000%, Time: 0:32:52 \n",
      "Iter:   1510, Train Loss: 0.03114, Train Acc: 98.4375%, Val Loss: 0.9323, Val Acc: 74.1333%, Time: 0:33:04 \n",
      "Iter:   1520, Train Loss: 0.01073, Train Acc: 100.0000%, Val Loss: 0.9003, Val Acc: 75.4667%, Time: 0:33:17 \n",
      "Iter:   1530, Train Loss: 0.02592, Train Acc: 98.4375%, Val Loss: 0.9008, Val Acc: 74.8667%, Time: 0:33:30 \n",
      "Iter:   1540, Train Loss: 0.0152, Train Acc: 100.0000%, Val Loss: 0.9398, Val Acc: 75.4000%, Time: 0:33:42 \n",
      "Iter:   1550, Train Loss: 0.03059, Train Acc: 98.4375%, Val Loss: 0.9336, Val Acc: 75.7333%, Time: 0:33:55 \n",
      "Iter:   1560, Train Loss: 0.05194, Train Acc: 98.4375%, Val Loss: 0.9136, Val Acc: 74.2000%, Time: 0:34:08 \n",
      "Iter:   1570, Train Loss: 0.03241, Train Acc: 100.0000%, Val Loss: 0.9325, Val Acc: 75.3333%, Time: 0:34:21 \n",
      "Iter:   1580, Train Loss: 0.1123, Train Acc: 95.3125%, Val Loss: 0.882, Val Acc: 75.6000%, Time: 0:34:33 \n",
      "Iter:   1590, Train Loss: 0.01945, Train Acc: 100.0000%, Val Loss: 0.8663, Val Acc: 75.2667%, Time: 0:34:46 \n",
      "Iter:   1600, Train Loss: 0.1726, Train Acc: 95.3125%, Val Loss: 0.8713, Val Acc: 74.4000%, Time: 0:34:58 \n",
      "Iter:   1610, Train Loss: 0.1182, Train Acc: 96.8750%, Val Loss: 0.8761, Val Acc: 75.2667%, Time: 0:35:10 \n",
      "Iter:   1620, Train Loss: 0.03414, Train Acc: 100.0000%, Val Loss: 0.8706, Val Acc: 74.7333%, Time: 0:35:23 \n",
      "Iter:   1630, Train Loss: 0.08656, Train Acc: 98.4375%, Val Loss: 0.856, Val Acc: 75.3333%, Time: 0:35:36 \n",
      "Iter:   1640, Train Loss: 0.1377, Train Acc: 95.3125%, Val Loss: 0.8719, Val Acc: 76.8000%, Time: 0:35:48 \n",
      "Iter:   1650, Train Loss: 0.01194, Train Acc: 100.0000%, Val Loss: 0.8715, Val Acc: 76.5333%, Time: 0:36:00 \n",
      "Iter:   1660, Train Loss: 0.09504, Train Acc: 96.8750%, Val Loss: 0.8619, Val Acc: 75.4000%, Time: 0:36:13 \n",
      "Iter:   1670, Train Loss: 0.07264, Train Acc: 96.8750%, Val Loss: 0.8285, Val Acc: 76.7333%, Time: 0:36:26 \n",
      "Iter:   1680, Train Loss: 0.05377, Train Acc: 98.4375%, Val Loss: 0.8608, Val Acc: 75.7333%, Time: 0:36:38 \n",
      "Epoch: 9\n",
      "Iter:   1690, Train Loss: 0.09854, Train Acc: 98.4375%, Val Loss: 0.8456, Val Acc: 74.8667%, Time: 0:36:51 \n",
      "Iter:   1700, Train Loss: 0.102, Train Acc: 96.8750%, Val Loss: 0.8484, Val Acc: 76.2667%, Time: 0:37:04 \n",
      "Iter:   1710, Train Loss: 0.1396, Train Acc: 93.7500%, Val Loss: 0.8646, Val Acc: 76.5333%, Time: 0:37:17 \n",
      "Iter:   1720, Train Loss: 0.07908, Train Acc: 98.4375%, Val Loss: 0.8864, Val Acc: 75.2000%, Time: 0:37:30 \n",
      "Iter:   1730, Train Loss: 0.005663, Train Acc: 100.0000%, Val Loss: 0.9266, Val Acc: 75.8000%, Time: 0:37:42 \n",
      "No optimization for a long time, auto-stopping...\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
